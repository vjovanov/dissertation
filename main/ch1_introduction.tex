%!TEX root = ../phd.tex
\chapter{Introduction}
\label{sct:introduction}

% How worlds infrastructure depends on high-productivity (elaborate what is high-productivity).
Infrastructure of our society depends on billions of lines of code executed in data-centers,
 mobile devices, in routers, on personal computers, and in controllers of various devices. There are
 several million programmers worldwide writing code mostly in \emph{general purpose programming languages}
 like JavaScript, Java, Python, C\#. Advancements in our society's IT infrastructure depend on
 productivity of programmers that program it.

% High-level of abstraction.
Modern programming languages allow programmers to concisely with a high-level of
 abstraction model their problems. This allows writing their programs in minimal
 number of lines of code (LoC) and understanding

% The performance is important for our environment.
The amount of energy used for computation is becoming significant portion of overall energy consumption. It is estimated
 that 5\% \todo{cite} of electricity in the United States is used for data-center computations\todo{cite} and since
 the year 2005 this percentage is in constant growth\todo{cite}. If we would write more efficient
 programs the IT infrastructure would consume proportionally less energy.

% Low-level specialized code and heterogeneous platforms
Writing efficient programs for the programmers usually leads to low productivity. To make programs
 efficient programmers must write them with low-level of abstraction\todo{cite} and hand-craft their
 programs for the particular platform where the program is executed\todo{cite}. The problem
 becomes even worse on \emph{heterogeneous platforms} where programmers are faced
 with multiple computing targets such as parallel CPUs, GPUs, and FPGAs. With heterogeneous
 platforms programmers need to specialize their programs for each target separately.

% General purpose programming languages won't cut it for achieving both high-productivity and specialized code.
%  - compiler general purpose
%  - language too broad for both high-performance
For compilers of high-level general purpose programming languages it is hard to remove
 the abstraction overheads and at the same time target heterogeneous platforms. The two main
 reasons general purpose compilers can not optimize programs are:\begin{itemize}
 \item General purpose compilers reason only about general computations and can not reason
   about \emph{specific domains} such as linear algebra and relational algebra.
 \item During compilation the compilers are faced with a overwhelming number of choices
   for optimization. Finding a specific solution that is optimal for a given platform in
   this wast space is in most cases impossible.
 \end{itemize}


\subsection{Domain-Specific Languages}
\label{sec:domain-specific-languages}

% DSLs restrict the domain, and use the knowledge about the domain to produce better code.
Domain-specific languages (DSLs) provide a restricted,
high-level, and user-friendly interface crafted for a specific domain.
Restricting the language to a particular domain allows programming at
a high level of abstraction while retaining good run-time performance
by leveraging domain knowledge for optimized code generation or
interpretation.  In certain cases, code can even be targeted at
heterogeneous computing environments~\cite{rompf_optimizing_2013}.

% Examples of super successful DSLs

The implementation of a usable \emph{external} (or \emph{stand-alone})
DSL requires building a parser, type-checker, and possibly a complete
tool chain consisting of IDE integration, debugging, and documentation
tools. This is a great undertaking that is often not justified by the
benefits of having an external DSL.  A promising alternative to
external DSLs are \emph{embedded DSLs} (\edsls)~\cite{Hudak96csur}
which are hosted in a general-purpose language and reuse its
facilities. For the purpose of the following discussion, we
distinguish between two main types of embeddings: \emph{shallow} and
\emph{deep} embeddings.

  \begin{itemize}
  \item In a shallowly embedded DSL, values of the embedded language
    are \emph{directly} represented by values in the host language.
    Consequently, terms in the host language that represent terms in
    the embedded language are evaluated directly into host-language
    values that represent DSL values. In other words, evaluation in
    the embedded language corresponds directly to evaluation in the
    host language.
  \item In a deeply embedded DSL, values of the embedded language are
    represented \emph{symbolically}, that is, by host-language data
    structures, which we refer to as the \emph{intermediate
      representation (IR)}. Terms in the host language that represent
    terms in the embedded language are evaluated into this intermediate
    representation. An additional evaluation step is necessary to
    reduce the intermediate representation to a direct representation.
    This additional evaluation is typically achieved through
    \emph{interpretation} of the IR in the host language, or through
    \emph{code generation} and subsequent \emph{execution}.
  \end{itemize}

% High-level of abstraction, good user interface, great performance, portable code.
An important advantage of deep embeddings over shallow ones is that DSL
  terms can be easily manipulated by the host language. This enables domain-specific
  optimizations~\cite{rompf_lightweight_2012,rompf_optimizing_2013}
  that lead to orders-of-magnitude improvements in program performance, and
  multi-target code generation~\cite{brown_heterogeneous_2011}.


% Introduce the DSL authors and DSL users.

% It is important that domain-speicfic languages. are

% Introduce how it is important that DSLs are user-friendly for the DSL user.

% And easy to develop for the DSL author.

% External DSLs wonderful.

% External DSLs rarely pay-off, hard, only SQL and matlab.
% Make this as a paragraph.

% Further, they quickly grow in a big language. Cite Erik Meier.

% Embedded DSLs come to the rescue.

% Shallow embedded DSLs. cite the {perl} I reviewed.

% Direct embedded DSLs.

% Deep embedded DSLs.

% Sometimes Directly embedded DSLs are fit for the task.

% Advantages, disadvantages, etc.

% Summarize in a table (DSL author, DSL user) x (performance, user-friendines, etc.)

% This thesis we tackle the problem. is thesis we tackle the problems with deeply embedded DSLs.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Part 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% Concealing the deep embedding.
%%

%
% Simple translation resolves all the problems with deep embedding of DSLs.
%

%
% Explain each chapter.
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Part 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%
% Generating the deep embedding.
%

% The translation has a problem, required dual embeddings.
% We reuse the translation to generate DLSs.


%
% Dynamic Compilation of DSLs
%

% Finally, we identify that dynamic compilation is hard to track in the deep embeddings.
% we propose a solution for simplifying dynamic compilation in domain-specific languages.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Part 3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% Evaluation of different approaches to partial evaluation.
%%

%%
%% Polyvariant Staging for Performance of Shallow DSLs
%%
\section{Terminology}
\label{sec:terminology}
% in production

% EDSL DSL used interchangeably


\chapter{Background}
\label{ch:background}

\section{The Scala Programming Language}
\section{Embedded Domain-Specific Languages}
\section{Partial Evaluation and Multi-Stage Programming}
% TODO
% Distinguish method and functions
% Universal method
% Pattern matching
% Prefixes
% Extension methods
% Type hierarchy
% Implicit arguments

In this section we provide background information necessary for understanding \yy's
implementation in Scala. We briefly explain the core concepts of Lightweight Modular Staging
\cite{rompf_lightweight_2012,rompf_optimizing_2013} and Scala Macros
\cite{burmako_scala_2013}. Throughout the paper we assume familiarity with
the basics of the Scala Programming Language~\cite{odersky_scala_2004}.
\subsection{Scala}
\subsection{Deep Embedding of DSLs with LMS}
\label{subsec:deep-embedding}

% LMS
Lightweight Modular Staging (LMS) is a
staging~\cite{taha_multi-stage_1997} framework and an embedded
compiler for developing deeply embedded DSLs.  LMS provides a library
of reusable language components organized as \emph{traits} (Scala's
first-class modules).  An \edsl developer selects traits containing
the desired language features, combines them through \emph{mix-in}
composition~\cite{odersky_scalable_2005} and adds DSL-specific
functionality to the resulting \edsl trait.  \edsl programs then
extend this trait, inheriting the selected LMS and \edsl language
constructs. \figref{lst:lms} illustrates this principle.  The trait
\code{VectorDSL} defines a simplified \edsl for creating and
manipulating vectors over some numeric type \code{T}.  Two LMS traits
are mixed into the \code{VectorDSL} trait: the \code{Base} trait
introduces core LMS constructs %(e.g., abstract type \code{Rep})
and the \code{NumericOps} trait introduces the \code{Numeric} type
class and the corresponding support for numeric operations.  The
bottom of the figure shows an example usage of the \edsl. The constant
literals in the program are lifted to the IR through \emph{implicit
  conversions} introduced by
\code{NumericOps}~\cite{oliveira_type_2010}.

\begin{figure}
\begin{listingtiny}
// The EDSL declaration
trait VectorDSL extends NumericOps with Base {
  object Vector {
    def fill[T:Numeric]
      (v: Rep[T], size: Rep[Int]): Rep[Vector[T]] =
      vector_fill(v, size)
  }

  implicit class VectorOps[T:Numeric]
    (v: Rep[Vector[T]]) {
    def +(that: Rep[Vector[T]]): Rep[Vector[T]] =
      vector_+(v, that)
  }
  // Operations vector_fill and vector_+ are elided
}

new VectorDSL { // EDSL program
  Vector.fill(1,3) + Vector.fill(2,3)
} // returns a regular Scala Vector(3,6)
\end{listingtiny}
\caption{\label{lst:lms} Minimal \edsl for vector manipulation.}
\end{figure}

% Rep types
All types in the \code{VectorDSL} interface are instances of the
parametric type \code{Rep[_]}.  The \code{Rep[_]} type is an abstract
type member of the \code{Base} LMS trait and abstracts over the
concrete types of the IR nodes that represent DSL operations in the
deep embedding.  Its type parameter captures the type underlying the
IR: \edsl terms of type \code{Rep[T]} evaluate to host language terms
of type \code{T} during \edsl execution.

% operations
Operations on \code{Rep[T]} terms are added by implicit conversions that are introduced in the \edsl scope. For example, the implicit class \code{VectorOps} introduces the \code{+} operation on every term of type \code{Rep[Vector[T]]}. In the example, the type class \code{Numeric} ensures that vectors contain only numerical values.

\todo{remove tool}
% Statement about successful use
LMS has been successfully used by in project Delite~\cite{brown_heterogeneous_2011,composition-ecoop2013} for building DSLs that support heterogeneous parallel computing. \edsls developed with Delite cover domains
such as machine learning, graph processing, data mining, etc. Due to its wide use and high performance we choose Delite as a back-end for \yy.


\subsection{Scala Macros}
\label{sec:scala-macros}

% What are scala macros and how are they defined.
Scala Macros~\cite{burmako_scala_2013} are a compile-time meta-programming
feature of Scala. Macros operate on Scala abstract syntax trees (ASTs): they
can construct new ASTs, or transform and analyze the existing Scala ASTs.
Macro programs can use common functionality of the Scala compiler like
error-reporting, type checking, transformations, traversals, and implicit
search.

\yy uses a particular flavor of Scala macros called \emph{def
  macros}, though we will often drop the prefix ``def'' for the
sake of brevity.  From a programmer's point of view, def macros
are invoked just like regular Scala methods.  However, macro
invocations are \emph{expanded} during compile time to produce new
ASTs.  Macro invocations are type checked both before and after
expansion to ensure that expansion preserves well-typedness.  Macros
have separated declarations and definitions: declarations are
represented to the user as regular methods while macro definitions
operate on Scala ASTs.  The arguments of macro method definitions are
the type-checked ASTs of the macro arguments.

%Users / Usage
For DSLs based on \yy we use a macro that accepts a single block of
code as its input. At compile time, this block is first type checked
against the interface of the direct embedding. Then, \yy applies the
generic transformation to translate the directly embedded AST to the
corresponding deeply embedded AST.  For example, given the following
DSL snippet, \yy produces the \code{VectorDSL} program in
\figref{lst:lms}:\vspace{3pt}
\begin{listingtiny}
  vectorDSL {
    Vector.fill(1,3) + Vector.fill(2,3)
  }
\end{listingtiny}

\subsection{Partial Evaluation}
\label{sec:partial-evaluation}
