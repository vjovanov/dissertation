%!TEX root = ../phd.tex
\chapter{Introduction}
\label{sct:introduction}

% How worlds infrastructure depends on high-productivity (elaborate what is high-productivity).
Infrastructure of our society depends on billions of lines of code executed in data-centers,
 mobile devices, in routers, on personal computers, and in controllers of various devices. There are
 several million programmers worldwide writing code mostly in \emph{general purpose programming languages}
 like JavaScript, Java, Python, and C\#. Advancements in our society's infrastructure depend on
 productivity of programmers that program it.

% High-level of abstraction.
Modern general purpose programming languages allow programmers to concisely, with a high-level of
 abstraction model their problems. This fosters writing programs in a minimal
 number of lines of code (LoC) and quickly understanding programs written by others.
 Unfortunately, abstraction comes with a cost: each layer of abstraction must be
 executed and uses more energy for computation.


% The performance is important for our environment.
The amount of energy used for computation is becoming a significant portion of the overall energy consumption in the world.
 It is estimated that 2\% \todo{cite} of electricity in the United States is used for data-center computations and since
 the year 2008 this percentage is in constant growth\todo{cite}. If we would write more efficient
 programs the IT infrastructure would consume proportionally less energy.

% Low-level specialized code and heterogeneous platforms
Writing efficient programs in general purpose programming languages leads to low productivity.
 To make programs efficient programmers must write them with low-level of abstraction\todo{cite} and hand-craft their
 programs for the particular platform where the program is executed\todo{cite}. The problem
 becomes even worse on \emph{heterogeneous platforms} where programmers are faced
 with multiple computing targets such as parallel CPUs, GPUs, and FPGAs. With heterogeneous
 platforms programmers must specialize their programs for each target separately.

% General purpose programming languages won't cut it for achieving both high-productivity and specialized code.
%  - compiler general purpose
%  - language too broad for both high-performance
\paragraph{Why compilers can not optimize high-level programs?} For compilers of general purpose programming languages it is hard to remove the abstraction overheads and at the same time target heterogeneous platforms. The two main
 reasons general purpose compilers can not achieve these goals are:\begin{itemize}

 \item General purpose compilers reason only about general computations and can not reason
   about \emph{specific domains} such as linear algebra and relational algebra. This reduces
   the number of possible optimizations they can apply to the programs and leads to
   slower execution.

 \item During compilation the compilers are faced with a overwhelming number of choices
   for optimization. Each choice exponentially increases the \emph{search space}
   that the compiler needs to explore. Finding a specific solution that is optimal
   for a given platform in this wast space is in most cases impossible. The only way
   to efficiently explore the was search space is to use the domain knowledge to guide
   the optimizer towards a close-to-optimal solution.
 \end{itemize}

% Domain-Specific Languages
\section{Domain-Specific Languages}
\label{sec:domain-specific-languages}

% DSLs restrict the domain, and use the knowledge about the domain to produce better code.
Domain-specific languages (DSLs) provide a restricted,
 high-level, and user-friendly interface crafted for a specific domain.
 Restricting the language to a particular domain allows programming at
 a high level of abstraction while retaining good run-time performance
 by leveraging domain knowledge for optimized code generation or
 interpretation.  In certain cases, code can even be targeted at
 heterogeneous computing environments~\cite{rompf_optimizing_2013}.

% With DSLs can both write at the high-level and generate specialized code.
DSLs allow users to write programs at the high-level of abstraction and at the
 same time highly optimize them for execution on different target platforms. The restricted interface allows the optimizer to extract the domain knowledge from user programs. This knowledge is then used to define larger space of possible program executions. Then the knowledge about the domain
 can further be used to guide the optimizer in exploring the space of possible program executions
 towards the close-to-optimal solution.

% Examples of super successful DSLs
Successful examples of a DSL is the Standard Query Language (SQL) with millions of users world wide.
 SQL concisely expresses the domain of data querying and uses the knowledge about linear algebra
 to optimize queries far better than programmers could. SQL, as such, provides the base for almost all
 enterprise applications in the world.

\subsection{Kinds of DSLs}
\label{sec:kinds-of-dsls}

DSLs the restricted interface

\paragraph{External DSLs.} The implementation of a usable \emph{external}
(or \emph{stand-alone}) DSL requires building a parser, type-checker, and possibly a complete
tool chain consisting of IDE integration, debugging, and documentation
tools. This is a great undertaking that is often not justified by the
benefits of having an external DSL. Except SQL and Matlab external domain specific
languages have rarely been developed to a mature-enough state for wide adoption.

Another perspective about external DSLs is that they start as small concise languages but
 end up as a general purpose language\todo{cite}. As DSLs become popular their  language designers
 can not resist the users demand for a features of general purpose languages. These features,
 as they are added later, usually do not fit well into the original language.
 For example, SQL in most databases supports constructs like loops, variables,
 and hash-maps which are hard to reason about and diverge from the domain of
 relational algebra.

\paragraph{Embedded DSLs.} A promising alternative to external DSLs are \emph{embedded DSLs} (\edsls)~\cite{Hudak96csur}. Embedded DSLs
are hosted in a general-purpose language and reuse large parts of its
infrastructure: \emph{i)} IDE support, \emph{ii)} tools (e.g., debuggers and code analysis), \emph{iii)} compilation pipeline (e.g.,
 parser, type-checker, optimizations, and code generation), and \emph{iv)} standard library. Due to
 the reuse of the standard library embedded DSLs already support constructs from general purpose languages and
 therefore usually do not uncontrollably grow.

For the purpose of the following discussion, we distinguish between two main types of embeddings: \emph{shallow} and
\emph{deep} embeddings.

  \begin{itemize}

  \item In a shallowly embedded DSL, values of the embedded language
    are \emph{directly} represented by values in the host language.
    Consequently, terms in the host language that represent terms in
    the embedded language are evaluated directly into host-language
    values that represent DSL values. In other words, evaluation in
    the embedded language corresponds directly to evaluation in the
    host language.

  \item In a deeply embedded DSL, values of the embedded language are
    represented \emph{symbolically}, that is, by host-language data
    structures, which we refer to as the \emph{intermediate
      representation (IR)}. Terms in the host language that represent
    terms in the embedded language are evaluated into this intermediate
    representation. An additional evaluation step is necessary to
    reduce the intermediate representation to a direct representation.
    This additional evaluation is typically achieved through
    \emph{interpretation} of the IR in the host language, or through
    \emph{code generation} and subsequent \emph{execution}.

  \end{itemize}


\section{Comparison of DSL Kinds}
\label{sec:comparison-of-dsl-kinds}
% What we will compare
In this section we will show a brief comparison of programmability and performance
 of different DSL kinds. As it is hard to quantify and exactly judge programmability,
 in the following discussion we will make binary decision whether DSLs are easy to
 program or not. Scientifically proving how programmable is a DSL kind would require
 numerous user studies which we did not perform, but we rather build on experiences
 from previous work.

% Comparison of different DSL types.
To compare programmability of different DSL types we introduce two types of programmers:\begin{itemize}
  \item {\bf DSL users} are people that use a DSL to model and solve their tasks. This is a larger group of
   programmers as, usually, there is more language users than language authors. Therefore, it is good
   to optimize the design of DSLs for this group of programmers.

  \item {\bf DSL authors} are the programmers that develop domain-specific languages. This
   group is smaller than DSL users, but is still very important. If developing a DSL is hard
   then it will be harder to introduce new DSLs and features of existing DSLs will be
   developed at a slower pace.
 \end{itemize}

\paragraph{External DSLs.} For the DSL users external DSLs are, in the ideal case, \emph{easy to program}. Given that
the DSL authors implement a good language, the language syntax is crafted for the domain
and easy to comprehend and write. Error reporting and tooling should be built such that DSL users
easily prevent, identify, and finally fix the errors in their programs.

For the DSL authors developing DSLs is a different story. Although, the development
process is not hard as DSL authors design their own compiler, the amount of work
required to build a ``language eco-system'' is tremendous. Therefore we categorize
external DSLs as \emph{hard to develop}.\todo{cite}

Finally, external DSLs have \emph{high performance}. The language and the compiler can be
designed such that they extract all domain-knowledge from user programs. This domain knowledge
can then be used to optimize programs. Good example of high-performance DSLs is Spiral~\todo{cite}
as in parts of their work they thoroughly examine the domain and explore the entire
search space in order to find optimal programs.


\paragraph{Shallowly embedded DSLs.} We categorize shallow DSLs as \emph{easy to program} for
 the DSL users but less so than the external DSLs. Syntax and error reporting of the host language
 typically can not be modified to perfectly fit the domain. However, languages with flexible syntax~\todo{cite} and
 powerful type systems can closely model most of the domains. Some host languages have language extensions for
 introducing extensible syntax~\todo{cite} and customizable error reporting~\todo{cite} further
 improving the interface of DSLs. Finally, shallow DSLs have perfect interoperability with
 the host language libraries as the values in the embedded language directly correspond
 to the values in the host language.

For the DSL authors basic shallowly embedded DSLs are \emph{easy to program} as their
 development is similar to development of host language libraries. This makes it easy
 to evolve the language and experiment with different features. For DSLs
 with complex error reporting or extensible syntax the development
 becomes more difficult for the DSL authors.

Shallowly embedded DSLs have \emph{low performance}. The lack of the intermediate representation
prevents exploiting the domain knowledge to implement optimizations. Further, having
a language with the high-level of abstraction leads to layers of indirection and, thus,
performance overheads~\todo{cite}.

\paragraph{Deeply embedded DSLs.} For the DSL users deeply embedded DSLs are not ideal,
 and we categorize them as \emph{hard to program}. The reification in the host language
 is inevitably leads to abstraction leaks~(\S \ref{sec:abstraction-leaks}) such as
 convoluted interfaces, difficult debugging, incomprehensible type errors, run-time error reporting,
 and others~(see \ref{sec:abstraction-leaks}).

For the DSL author developing a DSL in the deep embedding is \emph{not easy}. Unlike with
 external DSLs where the difficulty comes from the amount of work required to develop
 the language ecosystem, in deep embeddings it is difficult to fit reification in the host language.
 The DSL author is required to exploit complicated type system features to
 minimize the abstraction leaks caused by the deep embedding.

% High-level of abstraction, good user interface, great performance, portable code.
Deeply embedded DSLs have \emph{high performance}. An important advantage of deep embeddings over shallow ones is that DSL
  terms can be easily manipulated by the host language. This enables domain-specific
  optimizations~\cite{rompf_lightweight_2012,rompf_optimizing_2013}
  that lead to orders-of-magnitude improvements in program performance, and
  multi-target code generation~\cite{brown_heterogeneous_2011}.

Another advantage is that deeply embedded DSLs are compiled at host language run-time and therefore
 support dynamic compilation~\todo{cite}: values in the host language are treated as constants during
 DSL compilation. Dynamic compilation can improve performance in certain types of DSLs (e.g., \todo{reference matrices} and \todo{reference query languages}).


\paragraph{Comparison summary.} We summarize different DSL kinds in the \tabref{tbl:comparison}. In the table
we can see that no DSLs provide an ideal solution for DSL users, DSL authors, and high-performance.
Depending on the domain that is being targeted by the language some kinds of
DSLs might be more suitable than the others.

% Developing a DSL

\newcolumntype{Y}{>{\centering\arraybackslash}X}
\begin{table}[ht]
\caption{Compares different DSL kinds with respect to ease of programming and performance. The sign \checkmark means ``good'' and the sign X means ``bad''. }
\label{tbl:comparison}
\centering
\begin{tabularx}{\linewidth}{ X Y Y Y }
\toprule
                      &   External    &     Shallow    &   Deep       \\ \midrule
For DSL Users         &  \checkmark   &  \checkmark    &     X        \\
For DSL Authors       &     X         &  \checkmark    &     X        \\
Performance           &  \checkmark   &      X         &   \checkmark \\
\bottomrule
\end{tabularx}
\end{table}


\paragraph{Choosing the right DSL kind.}  Some DSLs greatly benefit from extracting
 the domain knowledge. Typically languages with well defined transformation
 rules (e.g., relational algebra, linear algebra, logical formulas, etc.) benefit the
 most as those rules can be used to define the space of possible transformations. The optimizer
 can then explore the space of possible executions and find the optimal one.

For languages whose domain allows transformations based on the domain knowledge either external or deeply embedded DSLs
 are a good fit. With those approaches the DSL author can extract the domain knowledge from the programs
 and use it for optimizations. Some DSL authors choose to use the deep embedding~(e.g., OptiML~\cite{sujeeth_optiml:_2011}) and some external DSLs~(e.g., WebDSL~\cite{groenewegen2008webdsl}). Both of these approaches
 are important--discussing which DSL kind is a better choice is out of the scope of this thesis.


Shallow embeddings, on the other hand, are a good fit for languages where exploiting domain knowledge
 is not beneficial and where DSL users need features of general purpose programming
 languages. Good examples of such DSLs are languages for generating formats like JSON
 and XML, testing frameworks, and Actors~\cite{haller2009scala}.


\section{Importance of Language Support for Embedded DSL}
\label{sec:importance-of-language-support}

% No approach to DSLs is good in all aspects.

% For embedded domain-specific. The deep
% It is important that domain-speicfic languages. are

However, embedded domain specific languages are recommended in many cases and there
the situation is far from ideal. Explain what is missing and how shallow DSLs are complementary
to deep ones.

% Introduce how it is important that DSLs are user-friendly for the DSL user.

\section{Improving Language Support for Embedded Domain-Specific Languages}
\label{sec:improving-language-support}

In this thesis we improve the language support for domain specific languages. The
thesis is divided in 3 parts. first, second and third.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Part 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% Concealing the deep embedding.
%%

%
% Simple translation resolves all the problems with deep embedding of DSLs.
%

%
% Explain each chapter.
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Part 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%
% Generating the deep embedding.
%

% The translation has a problem, required dual embeddings.
% We reuse the translation to generate DLSs.


%
% Dynamic Compilation of DSLs
%

% Finally, we identify that dynamic compilation is hard to track in the deep embeddings.
% we propose a solution for simplifying dynamic compilation in domain-specific languages.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Part 3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% Evaluation of different approaches to partial evaluation.
%%

%%
%% Polyvariant Staging for Performance of Shallow DSLs
%%
\section{Terminology}
\label{sec:terminology}
% in production

% EDSL DSL used interchangeably


\chapter{Background}
\label{ch:background}

\section{The Scala Programming Language}
\section{Embedded Domain-Specific Languages}
\section{Partial Evaluation and Multi-Stage Programming}
% TODO
% Distinguish method and functions
% Universal method
% Pattern matching
% Prefixes
% Extension methods
% Type hierarchy
% Implicit arguments

In this section we provide background information necessary for understanding \yy's
implementation in Scala. We briefly explain the core concepts of Lightweight Modular Staging
\cite{rompf_lightweight_2012,rompf_optimizing_2013} and Scala Macros
\cite{burmako_scala_2013}. Throughout the paper we assume familiarity with
the basics of the Scala Programming Language~\cite{odersky_scala_2004}.
\subsection{Scala}
\subsection{Deep Embedding of DSLs with LMS}
\label{subsec:deep-embedding}

% LMS
Lightweight Modular Staging (LMS) is a
staging~\cite{taha_multi-stage_1997} framework and an embedded
compiler for developing deeply embedded DSLs.  LMS provides a library
of reusable language components organized as \emph{traits} (Scala's
first-class modules).  An \edsl developer selects traits containing
the desired language features, combines them through \emph{mix-in}
composition~\cite{odersky_scalable_2005} and adds DSL-specific
functionality to the resulting \edsl trait.  \edsl programs then
extend this trait, inheriting the selected LMS and \edsl language
constructs. \figref{lst:lms} illustrates this principle.  The trait
\code{VectorDSL} defines a simplified \edsl for creating and
manipulating vectors over some numeric type \code{T}.  Two LMS traits
are mixed into the \code{VectorDSL} trait: the \code{Base} trait
introduces core LMS constructs %(e.g., abstract type \code{Rep})
and the \code{NumericOps} trait introduces the \code{Numeric} type
class and the corresponding support for numeric operations.  The
bottom of the figure shows an example usage of the \edsl. The constant
literals in the program are lifted to the IR through \emph{implicit
  conversions} introduced by
\code{NumericOps}~\cite{oliveira_type_2010}.

\begin{figure}
\begin{listingtiny}
// The EDSL declaration
trait VectorDSL extends NumericOps with Base {
  object Vector {
    def fill[T:Numeric]
      (v: Rep[T], size: Rep[Int]): Rep[Vector[T]] =
      vector_fill(v, size)
  }

  implicit class VectorOps[T:Numeric]
    (v: Rep[Vector[T]]) {
    def +(that: Rep[Vector[T]]): Rep[Vector[T]] =
      vector_+(v, that)
  }
  // Operations vector_fill and vector_+ are elided
}

new VectorDSL { // EDSL program
  Vector.fill(1,3) + Vector.fill(2,3)
} // returns a regular Scala Vector(3,6)
\end{listingtiny}
\caption{\label{lst:lms} Minimal \edsl for vector manipulation.}
\end{figure}

% Rep types
All types in the \code{VectorDSL} interface are instances of the
parametric type \code{Rep[_]}.  The \code{Rep[_]} type is an abstract
type member of the \code{Base} LMS trait and abstracts over the
concrete types of the IR nodes that represent DSL operations in the
deep embedding.  Its type parameter captures the type underlying the
IR: \edsl terms of type \code{Rep[T]} evaluate to host language terms
of type \code{T} during \edsl execution.

% operations
Operations on \code{Rep[T]} terms are added by implicit conversions that are introduced in the \edsl scope. For example, the implicit class \code{VectorOps} introduces the \code{+} operation on every term of type \code{Rep[Vector[T]]}. In the example, the type class \code{Numeric} ensures that vectors contain only numerical values.

\todo{remove tool}
% Statement about successful use
LMS has been successfully used by in project Delite~\cite{brown_heterogeneous_2011,composition-ecoop2013} for building DSLs that support heterogeneous parallel computing. \edsls developed with Delite cover domains
such as machine learning, graph processing, data mining, etc. Due to its wide use and high performance we choose Delite as a back-end for \yy.


\subsection{Scala Macros}
\label{sec:scala-macros}

% What are scala macros and how are they defined.
Scala Macros~\cite{burmako_scala_2013} are a compile-time meta-programming
feature of Scala. Macros operate on Scala abstract syntax trees (ASTs): they
can construct new ASTs, or transform and analyze the existing Scala ASTs.
Macro programs can use common functionality of the Scala compiler like
error-reporting, type checking, transformations, traversals, and implicit
search.

\yy uses a particular flavor of Scala macros called \emph{def
  macros}, though we will often drop the prefix ``def'' for the
sake of brevity.  From a programmer's point of view, def macros
are invoked just like regular Scala methods.  However, macro
invocations are \emph{expanded} during compile time to produce new
ASTs.  Macro invocations are type checked both before and after
expansion to ensure that expansion preserves well-typedness.  Macros
have separated declarations and definitions: declarations are
represented to the user as regular methods while macro definitions
operate on Scala ASTs.  The arguments of macro method definitions are
the type-checked ASTs of the macro arguments.

%Users / Usage
For DSLs based on \yy we use a macro that accepts a single block of
code as its input. At compile time, this block is first type checked
against the interface of the direct embedding. Then, \yy applies the
generic transformation to translate the directly embedded AST to the
corresponding deeply embedded AST.  For example, given the following
DSL snippet, \yy produces the \code{VectorDSL} program in
\figref{lst:lms}:\begin{lstparagraph}
vectorDSL {
  Vector.fill(1,3) + Vector.fill(2,3)
}
\end{lstparagraph}

\subsection{Partial Evaluation}
\label{sec:partial-evaluation}
