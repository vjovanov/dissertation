%!TEX root = ../phd.tex

\chapter{Concealing the Deep Embedding of Domain-Specific Languages}

% High-level of abstraction, good user interface, great performance, portable code.
Domain-specific languages (DSLs) provide a restricted,
high-level, and user-friendly interface crafted for a specific domain.
Restricting the language to a particular domain allows programming at
a high level of abstraction while retaining good run-time performance
by leveraging domain knowledge for optimized code generation or
interpretation.  In certain cases, code can even be targeted at
heterogeneous computing environments~\cite{rompf_optimizing_2013}.

The implementation of a usable \emph{external} (or \emph{stand-alone})
DSL requires building a parser, type-checker, and possibly a complete
tool chain consisting of IDE integration, debugging, and documentation
tools. This is a great undertaking that is often not justified by the
benefits of having an external DSL.  A promising alternative to
external DSLs are \emph{embedded DSLs} (\edsls)~\cite{Hudak96csur}
which are hosted in a general-purpose language and reuse its
facilities. For the purpose of the following discussion, we
distinguish between two main types of embeddings: \emph{shallow} and
\emph{deep} embeddings.

  \begin{itemize}
  \item In a shallowly embedded DSL, values of the embedded language
    are \emph{directly} represented by values in the host language.
    Consequently, terms in the host language that represent terms in
    the embedded language are evaluated directly into host-language
    values that represent DSL values. In other words, evaluation in
    the embedded language corresponds directly to evaluation in the
    host language.
  \item In a deeply embedded DSL, values of the embedded language are
    represented \emph{symbolically}, that is, by host-language data
    structures, which we refer to as the \emph{intermediate
      representation (IR)}. Terms in the host language that represent
    terms in the embedded language are evaluated into this intermediate
    representation. An additional evaluation step is necessary to
    reduce the intermediate representation to a direct representation.
    This additional evaluation is typically achieved through
    \emph{interpretation} of the IR in the host language, or through
    \emph{code generation} and subsequent \emph{execution}.
  \end{itemize}

  An important advantage of deep embeddings over shallow ones is that DSL
  terms can be easily manipulated by the host language. This enables domain-specific
  optimizations~\cite{rompf_lightweight_2012,rompf_optimizing_2013}
  that lead to orders-of-magnitude improvements in program performance, and
  multi-target code generation~\cite{brown_heterogeneous_2011}.
%

% Direct embedding

On the other hand, shallow embeddings typically suffer less from
\emph{linguistic mismatch}: this is particularly obvious for a class of shallow embeddings that we refer to as \emph{direct} embeddings. Direct embeddings preserve the intrinsic constructs of the host language ``on the nose''. That is, DSL
constructs such as \code{if} statements, loops, or function literals, as well
as primitive data types such as integers, floating-point numbers, or strings
are represented directly by the corresponding constructs of the host language.
%

% Deep embedding

% IR => Abstraction leaks
 % - convoluted interface, complicated type errors, restricting language features
 % - debugging

Deep \edsls{} intrinsically \emph{compromise programmer experience} by leaking their
implementation details (\sct{sec:abstraction-leaks}). Often, IR construction
is achieved through complex type system constructs that are, inevitably,
visible in the \edsl interface. This can lead to cryptic type errors
that are often incomprehensible to DSL users.
In addition, the IR complicates program debugging as programmers cannot easily
relate their programs to the code that is finally executed. Finally, the host
language often provides more constructs than the embedded language and the usage
of these constructs can be undesired in the DSL. If these constructs are generic in type
(e.g., list comprehensions or \code{try\\catch}) they can not be restricted in the embedded
language by using complex types (\sct{sec:abstraction-leaks}).

Ideally, we would like to complement the high performance of deeply
embedded DSLs, along with their capabilities for multi-target code
generation, with the usability of their directly embedded counterparts.
Reaching this goal turns out to
be more challenging than one might expect: let us compare the
interfaces of a direct embedding and a deep embedding of a simple
EDSL for manipulating vectors\footnote{
  All code examples are written in \emph{Scala}.  Similar techniques can
  be applied in other statically typed languages.  Cf.~\cite{carette_finally_2009,awesome,svenningsson_combining_2012}.}.
The direct version of the interface is declared as: \vspace{3pt}
\begin{listingtiny}
trait Vector[T] {
  def map[U](fn: T => U): Vector[U]
}
\end{listingtiny}
\vspace{3pt} The interface of the deep embedding, however,
fundamentally differs in the types: while the (polymorphic) \code{map}
operation in the direct embedding operates directly on values of some
generic type \code{T}, the deep embedding must operate on whatever
intermediate representations we chose for \code{T}. For our example,
we chose the abstract, higher-kinded type \code{Rep[T]} to represent
values of type \code{T} in the deep embedding: \vspace{3pt}
\begin{listingtiny}
trait Vector[T] {
  def map[U](fn: Rep[T => U]): Rep[Vector[U]]
}
\end{listingtiny}

\vspace{3pt} The difference in types is necessarily visible in the
signature and thus inevitably leaks into user programs.  This might seem like
a low price to pay for all the advantages offered by a deep embedding.
However, as we will see in \sct{sec:abstraction-leaks}, this
difference in types is at the heart of many of the inconveniences
associated with deep embeddings. How then, can we conceal
this fundamental difference?

% Related work (Interfaces are very similar. (Potentially polymorphic embedding)
In Forge~\cite{forge}, Sujeeth et al. propose maintaining two parallel
embeddings, shallow and deep, with a single interface equivalent to
the deep embedding.  In the shallow embedding, \code{Rep} is defined
to be the identity on types, that is \code{Rep[T] = T}, effectively
identifying IR types with their direct counterparts.  As a result,
shallowly embedded programs may be executed directly to allow for easy
prototyping and debugging.  In production, a simple ``flip of a switch''
enables the deep embedding.  Unfortunately, artifacts of the deep
embedding still leak to the user through the fundamentally ``deeply
typed'' interface. We would like to preserve the idiomatic interface
of the host language and completely conceal the deep embedding.

% Direct interface with meta-programming.
The central idea of this paper is the use of \emph{reflection} to convert
programs written in an unmodified direct embedding into their deeply
embedded counterparts.  Since the fundamental difference between the
interfaces of the two embeddings resides in their types, we employ a
configurable \emph{type translation} to map directly embedded
types $T$ to their deeply embedded counterparts $\ttrone{T}$. For our
motivating example the type translation is simply:
\[
\begin{array}{llll}
  \ttrone{T} &=& T   & \text{if $T$ is in type argument position,}  \\
  \ttrone{T} &=& \text{\code{Rep[}}T\text{\code{]}}& \text{otherwise}.
\end{array}
\]
In \sct{sec:translation} we describe this translation among several
others and discuss their trade-offs.

% What does Yin-Yang do?
Together with a corresponding translation on terms, the type
translation forms the core of \yy, a generic framework for DSL
embedding, that uses Scala's macros~\cite{burmako_scala_2013} to
reliably translate directly embedded DSL programs into corresponding
deeply embedded DSL programs.  The virtues of the direct embedding are
used during program development when performance is not of importance;
the translation is applied when performance is essential or
alternative interpretations of a program are required (e.g., for
hardware generation).  To avoid error prone maintenance of
synchronized direct and deep embeddings \yy reuses the core
translation to generate the deep embeddings based on the definition of
direct embeddings. Since the same translation is applied both for the
\edsl definition and the \edsl program the equivalence between the
embeddings is assured.

% Contributions
\yy{} contributes to the state of the art as follows:
\begin{itemize}

  \item It completely conceals leaky abstractions of deep EDSLs from the users.
  The virtues of the direct embedding are used for prototyping, while the deep
  embedding enables high-performance in production. The reliable translation
  ensures that programs written in the direct embedding will always be correct
  in the deep embedding. The core translation is described in \sct{sec:translation}.

  \item It restricts host language features in the direct \edsl{} based on the
  supported features of the deep \edsl{}. Specialized type checking of the
  translated direct \edsl{} displays comprehensible error-messages to the user.
  Language restriction is further described in \sct{sec:restricting}.

  \item It simplifies deep \edsl development and guarantees semantic equivalence
  between the direct embedding and the deep embedding by reusing the core
  translation to generate the deep \edsl definition out of the direct \edsl
  definition~(\sct{sec:deep-gen}).


\end{itemize}

%
% Evaluation summary
%
We evaluate \yy by generating 3 deep \edsls from their direct
embedding, and providing interfaces for 2 existing \edsls. The effects
of concealing the deep embedding and reliability of the translation
were evaluated on 21 programs (1284 LOC), from EDSLs
OptiGraph~\cite{composition-ecoop2013} and
OptiML~\cite{sujeeth_optiml:_2011}. In all programs combined the
direct implementation obviates 101 type annotations related to the
deep embedding. The complete evaluation is presented in
\sct{sec:ch2-evaluation}.

Throughout the paper, we target the LMS~\cite{rompf_lightweight_2012}
framework as a deep embedding back-end due to the plethora of existing
LMS \edsls.  Consequently, we will assume that deep embeddings use
LMS' extensible IR.  However, \yy is applicable to other types of IR
(e.g., polymorphic embeddings~\cite{hofer_polymorphic_2008}) and
possibly other statically typed languages (\sct{sec:other-languages}).

\section{Motivation}
\label{sec:motivation}

% What do we describe in this Section
The main idea of this paper is that \edsl{} users should program in a
direct embedding, while the corresponding deep embedding should be used only in production.
To motivate this idea we consider the direct embedding and the deep embedding of a simple \edsl for manipulating vectors. Here, we use Scala to show the problems with the deep embedding that apply to other statically typed programming languages (e.g., Haskell and OCaml). These languages achieve the embedding in different ways~\cite{svenningsson_combining_2012,awesome,carette_finally_2009,guerrero_implementing_2004}, but this is always reflected in the type signatures. In the context of Scala, there are additional problems with type inference and implicit conversions, however, we omit those from the discussion as language specific.

% Shallow Embedding in Scala
\figref{lst:vector} shows a simple direct \edsl{} for manipulating numerical vectors.
Vectors are instances of a \code{Vector} class, and have only two operations:
\emph{i)} vector addition (the \code{+}), and \emph{ii)} the higher-order \scode{map} function which applies a function \code{f} to each element of the vector. The \code{Vector} object provides factory methods \code{fromSeq}, \code{range}, and \code{fill} for vector construction. Note that though the type of the elements in a vector is generic, we require it to be an instance of the \code{Numeric} type class.

\begin{figure}
\begin{listingtiny}
object Vector {
  def fromSeq[T: Numeric](seq: Seq[T]): Vector[T] =
    new Vector(seq)
  def fill[T: Numeric](v: T, size: Int): Vector[T] =
    fromSeq(Seq.fill(size)(v))
  def range(start: Int, end: Int): Vector[Int] =
    fromSeq(Seq.range(start, end))
}
class Vector[T: Numeric](val data: Seq[T]) {
  def map[S: Numeric](f: T => S): Vector[S] =
    Vector.fromSeq(data.map(x => f(x)))
  def +(that: Vector[T]): Vector[T] =
    Vector.fromSeq(data.zip(that.data)
      .map(x => x._1 + x._2))
}

\end{listingtiny}
\caption{\label{lst:vector} The interface of a direct \edsl for manipulating numerical vectors.}
\end{figure}

For a programmer, this is an easy to use library. Not only can we write
expressions such as \code{v1 + v2} for summing vectors (resembling mathematical
notation), but we can also get meaningful type error messages. The \edsl is an
idiomatic Scala and displayed type errors are comprehensible. Finally, in the
direct embedding, all terms directly represent values from the embedded language
and inspecting intermediate values with the debugger is straightforward.

The problem, however, is that the code written in such a direct embedding suffers from major performance issues \cite{rompf_optimizing_2013}. For some intuition, consider the following code for adding 3 vectors: \code{v1 + v2 + v3}. Here, each \code{+} operation creates an intermediate \code{Vector} instance, uses the \code{zip} function, which itself creates an intermediate \code{Seq} instance, and calls a higher-order \code{map} function. The abstractions of the language that allow us to write code with high-level of abstraction have a downfall in terms of performance. Consecutive vector summations would perform much better if they were implemented with a simple while loop.

% Deep Embedding
\subsection{The Deep Embedding}
For the DSL from \figref{lst:vector}, the overhead could be eliminated with
optimizations like stream fusion~\cite{coutts_stream_2007} and inlining, but to
properly exploit domain knowledge, and to potentially target other platforms,
one must introduce an intermediate representation of the \edsl program. The
intermediate representation can be transformed according to the domain-specific rules
 (e.g., eliminating addition with a null vector) to improve performance beyond common compiler
optimizations~\cite{rompf_optimizing_2013}. To this effect, we use the LMS
framework and present the deep version of the \edsl{} for manipulating numerical vectors in
\figref{lst:vector_deep}.

In the \code{VectorDSL} interface every method has an additional implicit
parameter of type \code{SourceContext} and every generic type requires an
additional \code{TypeTag} type class. The \code{SourceContext} contains information
about the current file name, line number, and character offset.
\code{SourceContext}s are used for mapping generated code to the original
program source. \code{TypeTag}s carry all information about the type of terms.
They are used to propagate run-time type information through the \edsl{}
compilation for optimizations and generating code for statically typed target
languages. In the \edsl definitions the \code{SourceContext} is rarely used
explicitly (i.e., as an argument). It is provided ``behind the scenes'' by implicit
definitions that are provided in the DSL.

\begin{figure}
\begin{listingtiny}
trait VectorDSL extends Base {
  object Vector {
    def fromSeq[T:Numeric:TypeTag](seq: Rep[Seq[T]])
      (implicit sc: SourceContext): Rep[Vector[T]] =
      vector_fromSeq(seq)
    def fill[T:Numeric:TypeTag]
      (value: Rep[T], size: Rep[Int])
      (implicit sc: SourceContext): Rep[Vector[T]] =
      vector_fill(value, size)
    def range(start: Rep[Int], end: Rep[Int])
      (implicit sc: SourceContext):Rep[Vector[Int]]=
      vector_range(start, end)
  }

  implicit class VectorRep[T:Numeric:TypeTag]
    (v: Rep[Vector[T]]) {
    def data
      (implicit sc: SourceContext): Rep[Seq[T]] =
      vector_data(v)
    def +(that: Rep[Vector[T]])
      (implicit sc: SourceContext):Rep[Vector[T]] =
      vector_plus(v, that)
    def map[S:Numeric:TypeTag](f: Rep[T] => Rep[S])
      (implicit sc: SourceContext): Rep[Vector[S]] =
      vector_map(v, f)
  }

  // IR constructors for `map` and `plus` are elided
  case class VectorFill[T:TypeTag]
    (v: Rep[T], s: Rep[Int])
    (implicit sc: SourceContext)
  def vector_fill[T:Numeric:TypeTag]
    (v: Rep[T], size: Rep[Int])
    (implicit sc: SourceContext): Rep[Vector[T]] =
    VectorFill(v, size) // IR node construction
}
\end{listingtiny}
\caption{\label{lst:vector_deep} A LMS based deep \edsl{} for manipulating numerical vectors.}
\end{figure}

\subsection{Abstraction Leaks in the Deep Embedding}
\label{sec:abstraction-leaks}

The programs in the deep embedding construct the IR instead of the values in the embedded language. This inevitably leaks to the users in the following ways:

\paragraph{Convoluted interfaces.} The interface of the \edsl has \code{Rep[_]}
types in all its method signatures. Furthermore, once we introduce code
generation, the method signatures must be enriched with source and type
information (\code{SourceContext} and \code{TypeTag}) and inevitably become
complex. This makes the interface very complicated to understand. The user of
the \edsl{}, who might not be an expert programmer, needs to understand concepts
like \code{TypeTag} and \code{SourceContext} to grasp the interface.

% Debugging, returns just Case class instantiation.

\paragraph{Difficult debugging.} In the methods of the direct \edsl{} all terms
directly represent values in the embedded language (there is no intermediate
representation). This allows users to trivially use debugging tools to step
through the terms and inspect the values of the embedded language. With the deep
\edsl{}, method definitions only instantiate the IR nodes. In the classical
debugging mode this does not convey any useful information to the user.
Furthermore, debugging generated code or an interpreter is extremely difficult.
Users cannot relate the debugger position and the original line of code.

\paragraph{Complicated type errors.} The \code{Rep[_]} types leak to the user through type errors. Even for simple type errors the user is exposed to non-standard error messages. In certain cases (e.g., incorrect call to an overloaded function), the error messages can become hard to understand. To illustrate, we present a typical type error for invalid method invocation:
\begin{lstparagraph}
  found   : Int(1)
  required: Vector[Int]
       x + 1
           ^
\end{lstparagraph}
In the deep embedding the corresponding type error contains \code{Rep} types and the \code{this} qualifier:
\begin{lstparagraph}
  found   : Int(1)
  required: this.Rep[this.Vector[Int]]
       (which expands to) this.Rep[vect.Vector[Int]]
       x + 1
           ^
\end{lstparagraph}
This example represents one of the  most common type errors. For more complicated type errors
\todo{cf.}~\cite{techrep}. \paragraph{Unrestricted host language constructs.} In the deep embedding all
generic constructs of a host language can be used arbitrarily. For example,
\code{scala.List.fill[T](count: Int, el: T)} can, for the argument \code{el}, accept
both direct and deep terms. This is often undesirable as it can lead
 to code explosion and unexpected program behavior.

In the following example, assume that generic methods \code{fill} and
\code{reduce} are not masked by the \code{VectorDSL} and belong only to the host
language library. In this case, the invocation of \code{fill} and \code{reduce}
performs meta-programming over the IR of the deep embedding:\vspace{3pt}

\begin{listingtiny}
  new VectorDSL {
    List.fill(1000, Vector.fill(1000,1)).reduce(_+_)
  }
\end{listingtiny}\vspace{3pt}

Here, at DSL compilation time, the program creates a Scala list that contains a thousand
IR nodes for the \code{Vector.fill} operation and performs a vector addition over them.
Instead of producing a small IR the compilation result is a thousand IR nodes for
vector addition. This is a typical case of code explosion that could not happen
in the direct embedding which does not introduce an IR.

On the other hand, some operations can be completely ignored. In the next
example, the \code{try/catch} block will be executed during \edsl compilation
instead during DSL program execution:\vspace{3pt}

\begin{listingtiny}
  new VectorDSL {
    try Vector.fill(1000, 1) / 0
    catch { case _ => Vector.fill(1000, 0) }
  }
\end{listingtiny}

Here, the resulting program always throws a \code{DivisionByZero}
exception.

\section{Translation of the Direct Embedding}
\label{sec:translation}

% Set up the problem.
The purpose of the core \yy translation is to reliably and automatically make
a transition from a directly embedded DSL program to its deeply embedded
counterpart. The transition requires a translation for the following reasons:
\emph{i)} host language constructs such as \code{if} statements are strongly
typed and accept only primitive types for some of their arguments (e.g., a
condition has to be of type \code{Boolean}), \emph{ii)} all types in the direct
embedding need to be translated into their IR counterparts (e.g., \code{Int} to
\code{Rep[Int]}), \emph{iii)} the directly embedded DSL operations need to be
mapped onto their deeply embedded counterparts, and \emph{iv)} methods defined
in the deep embedding require additional parameters, such as run-time type
information and source positions. To address these inconsistencies we propose a
straightforward solution: a type-directed program translation from direct to
deep embeddings.

% Overview of the solution:
Since the translation is type-directed it requires reflection that supports
 \emph{type introspection} and \emph{type transformation}. The translation is based on the idea of representing language constructs as method calls~\cite{carette_finally_2009,rompf_scala-virtualized:_2009} and systematically intrinsifying direct DSL operations and types of the direct embedding to their deep counterparts~\cite{carette_finally_2009}. The translation operates in two main steps:
\begin{description}
\item[Language virtualization] converts host language intrinsics into
  function calls, which can then be evaluated to the appropriate IR
  values in the deep embedding.
\item[\edsl{} intrinsification] converts DSL intrinsics (operations
  and types) from the direct embedding into their deep counterparts.
\end{description}



\begin{figure*}[!ht]
\begin{multicols}{2}
\begin{subfigure}[b]{1\linewidth}
\centering
\vspace{1.4em}
\begin{listingtiny}
import vector._; import math.pow;
val n = 100; val exp = 6;
vectorDSL {
  if (n > 0) {
    val v = Vector.range(0, n)
    v.map(x => pow(x, exp)).sum
  } else 0
}
\end{listingtiny}
\vspace{1.4em}
\caption{A program in direct embedding for calculating $\sum_{i=0}^n i^{exp}$.}
\label{lst:direct-embedding}
\end{subfigure}

\begin{subfigure}[b]{1\linewidth}
\centering
\begin{listingtiny}
val n = 100; val exp = 6;
vectorDSL {
  if (n > 0) {
    val v: Vector[Int] =
      vector.Vector.range(0, n)
    v.map[Int](x: Int =>
      math.`package`.pow(x, exp)
    ).sum[Int](math.Numeric.IntIsIntegral)
  } else 0
}
\end{listingtiny}
\caption{The original program after desugaring and type inference.}
\label{lst:desugaring}
\end{subfigure}

\end{multicols}

\begin{subfigure}[b]{1\linewidth}
\begin{listingtiny}
val n = 100; val exp = 6;
new VectorDSL with IfOps
  with MathOps { def main() = {
  ifThenElse[Int](
    hole[Int](typeTag[Int], 0) > lift[Int](0),{
    val v: Rep[Vector[Int]] =
      valDef[Vector[Int]](
        this.Vector.range(
          lift[Int](0),
          hole[Int](typeTag[Int], 0)))
    v.map[Int](lam[Int, Int](x: Rep[Int] =>
      this.`package`.pow(
        x,
        hole[Int](typeTag[Int], 1))
    ).sum[Int](this.Numeric.IntIsIntegral)
  },{
    lift[Int](0)
  }
)}
\end{listingtiny}
\caption{The \yy translation of the program from \figref{lst:desugaring}.}
\label{lst:transformed_program}

\end{subfigure}
\caption{\label{fig:translation-example} Transformation of an EDSL program for calculating $\sum_{i=0}^n i^{exp}$.}
\end{figure*}

\todo{Tie this example in and fix it and talk more about it after the different back-ends are introduced.}
To illustrate the core translation, we use an example program for calculating $\sum_{i=0}^n i^{exp}$ using the vector \edsl defined in \figref{lst:vector}. \figref{fig:translation-example} contains three versions of the program: Figure \ref{lst:direct-embedding} depicts the direct embedding version, Figure \ref{lst:desugaring} represents the program after type checking (as the translation sees it), and Figure \ref{lst:transformed_program} shows the result of the translation.

\subsection{Language Virtualization}
\label{sct:langauge-virtualization}
Language virtualization allows to redefine intrinsic constructs of the
host language, such as \code{if} and \code{while} statements. This can be
achieved by translating them into suitable method invocations as shown by Rompf
et al. in the modified Scala compiler named Scala-Virtualized~\cite{rompf_scala-virtualized:_2009}.

 \yy follows the ideas of Carette et al.~\cite{carette_finally_2009}
 and Scala-Virtualized but virtualizes all Scala expressions and uses macros of
  unmodified Scala to virtualize its intrinsics. Practice has shown that DSL
  authors are reluctant to use a modified compiler and that for the wide adoption
  of embedded DSLs it is important to provide a solution based on unmodified Scala.

 Compared to Scala-Virtualized we translate additional language constructs:
  function/method definition and function application, exception handling, and all kinds of value-binding constructs
  (i.e., values, lazy values, and variables). Translation rules for supported language constructs are
  represented in~\figref{fig:virt-core} with $\ttrone{t}$ denoting the translation of a term $t$. In some expressions
  the original types are introspected and used as a type argument of the corresponding virtualized method. These
  generic types are later translated to the deep embedding during the DSL intrinsification phase.

  \begin{figure}[!ht]
%
%  Functions
%
    \judgement{Function Virtualization}{}

\begin{multicols}{2}
    \infyy{}
      {\tctx{\Gamma}{t: T_2}}
      {x: T_1 \Rightarrow t}{\mathtt{lam}[T_1,T_2](x: T_1 \Rightarrow \trone{t})}

    \infyy{}
      {\tctx{\Gamma}{t_1:\;\Func{T_1}{T_2} \quad t_2: \; T_1}}
      {t_1(t_2)}{\mathtt{app}[T_1,\;T_2](\ttrone{t_1},\; \ttrone{t_2})}
\end{multicols}

\vspace{1.5em}
\judgement{Method Virtualization}{}
\vspace{1em}

   \infyyax{}
      {\mathbf{def}\;f[T_1](x:T_2):T_3 {=} t}{\mathbf{def}\;f[T_1]:(T_2 {\Rightarrow} T_3){=}\trone{x:T_2 {\Rightarrow} t}}

    \infyy{}
      {\tctx{\Gamma}{t_1.f: [T_1](\Func{T_2}{T_3})}}
      {t_1.f[T_1](t_2)}{\mathtt{app}[T_2,T_3](\ttrone{t_1}.f[T_1],\ttrone{t_2})}
%
% Control constructs
%
\vspace{1.5em}
\judgement{Control Constructs}{}
\vspace{1em}
    \infyy{}
      {\tctx{\Gamma}{\mathbf{if}(t_1) \;t_2\; \mathbf{else}\;t_3: T}}
      {\mathbf{if}(t_1) \;t_2\; \mathbf{else}\;t_3}{\mathtt{ifThenElse}[T](\ttrone{t_1}, \ttrone{t_2}, \ttrone{t_3})}

    \infyy{}
          {\tctx{\Gamma}{\mathbf{try}\;t_1\;\mathbf{catch}\;t_2\;\mathbf{finally}\;t_3:\;T }}
          {\mathbf{try}\;t_1\;\mathbf{catch}\;t_2\;\mathbf{finally}\;t_3\; }{\mathtt{tryCatch}[T](\ttrone{t_1},\;\ttrone{t_2},\;\ttrone{t_3})}
    \vspace{0.05em}

\begin{multicols}{2}
    \infyyax{}
      {\mathbf{while}(c)\;b}{\mathtt{whileDo}(\ttrone{c},\;\ttrone{b})}

    \infyyax{}
      {\mathbf{do}\; b \;\mathbf{while}(c)}{\mathtt{doWhile}(\ttrone{c},\;\ttrone{b})}
\end{multicols}

    \infyyax{}
      {\mathbf{return}\; t}{\mathtt{ret}(\ttrone{t})}

%
% Varibles
%
\vspace{1.5em}
\judgement{Value Bindings}{}
\vspace{1em}

\infyyax{}
      {\mathbf{lazy\;val}\;x:T = t}{\mathbf{val}\;x:T = \mathtt{lazyValDef}[T](\ttrone{t})}

\begin{multicols}{2}
    \infyyax{}
      {\mathbf{val}\;x:T = t}{\mathbf{val}\;x:T = \mathtt{valDef}[T](t)}

    \infyyax{}
      {\mathbf{var}\;x:T = t}{\mathbf{val}\;x:T = \mathtt{varDef}[T](\ttrone{t})}
\end{multicols}

\begin{multicols}{2}
    \infyy{}
      {\tctx{\Gamma}{x: T}}
      {x}{\mathtt{read}[T](\ttrone{x})}

    \infyy{}
      {\tctx{\Gamma}{x: T}}
      {x = t}{\mathtt{assign}[T](x, \ttrone{t})}
\end{multicols}

\caption{Rules for virtualization of Scala language intrinsics.}
\label{fig:virt-core}
\end{figure}


% Binding taken care of by DSL intrinsification.
 Defined translation rules convert language constructs into method calls where each language construct has
  a corresponding method. The signature of each method is partially defined by \yy. Method names, the number of
  type parameters and the number of type arguments are predefined while types of arguments and return types
  are open for the DSL author to define. \todo{link to the signature}

 Binding of the translated language constructs to the corresponding methods
  in the deep embedding is achieved during DSL intrinsification; language virtualization is
  agnostic of this binding. Further, in the implementation, all method names are prepended with $\$$
  \footnote{In Scala it is a convention that user defined method's names should not contain $\$$ characters as those are reserved for the name mangling performed by the Scala compiler.} which avoids collisions with other user functions.

 % Discuss the function translation.
 \paragraph{Functions.} We virtualize function definition and application to support full abstraction over the host
  language expressions. This allows DSL authors to define how functions are treated by
  reifying them and optionally providing analysis and transformations over them. For example, DSL authors
  can define different inlining strategies, perform call graph analysis, or instrument all function calls. With Scala-Virtualized
  this is not possible as functions are not translated and thus it is impossible to
  abstract over them.

% Discuss method translations.
 \paragraph{Methods.} Method definitions follow a similar philosophy as functions.
  The difference is that in Scala, the \code{def} keyword is used to define universal quantification and possibly recursion.
  This is similar to the \code{let} and \code{letrec} constructs in other functional languages. This translation is optional
  as in some DSLs it is more concise to reuse method application of the host language.
  \todo{Name collision.}

% Discuss control structures.
 \paragraph{Control constructs.} We translate all Scala control constructs (e.g.,\code{if} and \code{try} to method calls.
  Scala's type system supports parametric polymorphism, by-name parameters, and partial functions that can model
  the semantics of all constructs. How these features are used to model the original constructs is presented~\todo{}.

% Discuss variables.
 \paragraph{Value bindings.} Scala has multiple constructs for value binding: values, variables, and lazy values. \yy translates
  definition of values into methods as well as all accesses. Abstraction over values accesses is
  necessary for tracking effects in case of variables, access order in case of lazy values, and instrumentation
  in case of simple values.

 \paragraph{Universal methods.} Scala is designed such that the types \code{Any} and
 \code{AnyRef}, which reside at the top of the Scala class hierarchy, contain
 \code{final} methods. Through inheritance, these methods are defined on all
 types making it impossible to override their functionality without translation.

 \yy virtualizes all methods on types \code{Any} and \code{AnyRef}. Method calls on objects
  are translated into the representation where the \code{this} pointer is passed as the first argument and, by convention, all methods start
  with a prefix \code{infix_}.

  This representation is convenient for methods that are defined once for the whole hierarchy as
  the DSL author needs to define this method only once, as opposed to adding it to each data type. The caveat with
  this approach is that in case of methods that are overridden the virtual dispatch must be
  performed manually by the DSL author.

  For DSLs that require extension of these methods we provide an alternative translation
  of universal methods into the name mangled infix form:

  \infyyax{}
      {t_1\; == \;t_2}{\trone{t_1}.\;\mathtt{\_\_==}(\;\trone{t_2})}

  \todo{new}

\begin{figure}[!ht]
%
% Virtualization of `Any` methods
%
% *   t == t1                =>       infix_==(t, t1)
\judgement{Methods on the \code{Any} type}{}
\begin{multicols}{2}
    \infyyax{}
      {t_1\; == \;t_2}{\mathtt{infix\_==}(\trone{t_1},\;\trone{t_2})}

% *   t != t1                =>       infix_!=(t, t1)
    \infyyax{}
      {t_1\;!=\;t_2}{\mathtt{infix\_!=}(\trone{t_1},\;\trone{t_2})}
\end{multicols}

% *   t.##                   =>       infix_##(t)
\begin{multicols}{2}
    \infyyax{}
      {t.\#\#}{\mathtt{infix\_\#\#}(\trone{t})}
    \infyyax{}
      {t.\mathtt{getClass}}{\mathtt{infix\_getClass}(\trone{t})}
\end{multicols}

% *   t.isInstanceOf[T]      =>       infix_isInstanceOf[T](t)
    \infyyax{}
      {t.\mathtt{isInstanceOf[T]}}{\mathtt{infix\_isInstanceOf[T]}(\trone{t})}

% *   t.asInstanceOf[T]      =>       infix_asInstanceOf[T](t)
    \infyyax{}
      {t.\mathtt{asInstanceOf[T]}}{\mathtt{infix\_asInstanceOf[T]}(\trone{t})}

%
% Virtualization of `AnyRef` methods
%
\vspace{1em}
\judgement{Methods on the \code{AnyRef} type}{}

 \begin{multicols}{2}
 % *   t eq t1                =>       infix_eq(t, t1)
   \infyyax{}
     {t_1\;\mathtt{eq}\;t_2}{\mathtt{infix\_eq}(\trone{t_1},\;\trone{t_2})}

 % *   t ne t1                =>       infix_ne(t, t1)
   \infyyax{}
     {t_1\;\mathtt{ne}\;t_2}{\mathtt{infix\_ne}(\trone{t_1},\;\trone{t_2})}
\end{multicols}

\begin{multicols}{2}
% *   t.wait(t1, l)          =>       infix_wait(t, t1, l)
   \infyyax{}
      {t_1.\mathtt{wait}(t_2,\;t_3)}{\mathtt{infix\_wait}(\trone{t_1},\;\trone{t_2},\;\trone{t_3})}
    % *   t.wait(l)              =>       infix_wait(t, l)
  \infyyax{}
     {t_1.\mathtt{wait}(t_2)}{\mathtt{infix\_wait}(\trone{t_1},\;\trone{t_2})}
\end{multicols}
\vspace{-2.7em}
\begin{multicols}{2}
% *   t.wait                 =>       infix_wait(t)
   \infyyax{}
     {t.\mathtt{wait}}{\mathtt{infix\_wait}(\trone{t})}

% *   t.notify               =>       infix_notify(t)
   \infyyax{}
     {t.\mathtt{notify}}{\mathtt{infix\_notify}(\trone{t})}

\end{multicols}

 % *   t.notifyAll            =>       infix_notifyAll(t)
   \infyyax{}
     {t.\mathtt{notifyAll}}{\mathtt{infix\_notifyAll}(\trone{t})}

% *   t.synchronized[T](t1)  =>       infix_synchronized(t, t1)
  \infyyax{}
     {t_1.\mathtt{synchronized}[T](t_2)}{\mathtt{infix\_synchronized}[T](\trone{t_1},\;\trone{t_2})}

\caption{Rules for virtualization of methods on \code{Any} and \code{AnyRef}.}
\label{fig:virt-any}
\end{figure}


 \paragraph{Not virtualizing class definitions.} \yy does not virtualize class and trait definitions, including the \emph{case class}
  definitions. For the given set of DSL compiler frameworks that use \yy it was hard to identify
  an abstraction that would allow virtualization of Scala classes.

  This limitation, however, does not preclude class virtualization for embedded DSLs. We allow extensions to \yy that virtualize classes and traits
  through the use of the reflection API. The drawback of this approach is that DSL authors are required
  to know the reflection API compared to the simple interface of language virtualization. For now, each framework that uses \yy defines
  its own translation scheme. Extending \yy to achieve class virtualization is described in \todo{cf. extensions}.

 \paragraph{Configuring method virtualization.} When we virtualize methods and their application
   we effectively override all expressions of Scala. In this case the DSL author has to:
   \emph{i)} write the DSL definition in a way that corresponds to the translation and is not idiomatic to Scala,
   and \emph{ii)} do additional transformation that removes all combinations of applications over domain-specific operations.

   This can be cumbersome and we leave method virtualization as a configuration option that is
    disabled by default. This way DSL authors can write DSLs in the
    Scala idiomatic way and the \code{app}/\code{lam} pairs for DSL operations never appear in the
    DSL intermediate representation.


% Name of type translation.
\newcommand{\ttname}{\tau}

% Type translations (Vojin-style).
%\newcommand{\ttarg}[1][-]{\ttname(#1, \mathtt{arg})}     % type arguments
%\newcommand{\ttother}[1][-]{\ttname(#1, \mathtt{other})} % other

% Type translations (Sandro-style).
\newcommand{\ttarg}[1][]{\ttname_{\mathtt{arg}} \ifempty{#1}{}{(#1)}}
%\newcommand{\ttother}[1][]{\ttname_{\mathtt{oth}} \ifempty{#1}{}{(#1)}}
\newcommand{\ttother}[1][]{\ttname \ifempty{#1}{}{(#1)}}

\subsubsection{Virtualizing Pattern Matching}
\label{sct:virtpatmat}

% Define how it works.
The Scala compiler has a virtual pattern matcher that allows for changing the semantics
 of the construct. The semantics can be changed to reify the pattern match for its use
 in DSLs or to provide alternative \yy reuses the functionality of this pattern matcher
 in combination with DSL intrinsification to allow reasoning about it in DSL compilers.
 In this section, for purposes of explaining DSL intrinsification, we explain the functioning
 of the virtualized pattern matcher.

% Semantics of Scala pattern matching: alternatives are interpreted with a plus and failures with a zero, and guards as filters. We also need a constructor one. Example of Option.
Scala's pattern matching can be interpreted with deconstructors and operations on the \code{Option}
 type of Scala. The successful match is represented with the \code{Some} type which is
 a constructed the monadic return of the \code{Option} monad; failures failures with the
 \code{None} type which is a monadic \emph{zero} operation.
 The pattern nesting is represented with the monadic \emph{bind} operation \code{flatMap}; alternation is represented with the
 \code{orElse} combinator on the \code{Option} monad which represents monadic addition. The semantics
 of Scala pattern matching can be represented completely with the operations of the zero-plus monad.


% Based on the fact that Scala pattern matching can be interpreted as a zero+ monad.
The virtual pattern matcher converts Scala pattern matching to the operations on a user-defined zero-plus monad.
A pattern match is virtualized if the object \code{__match} is defined in the scope. For the original
semantics of Scala pattern matching is defined by the object \code{__match} defined in \figref{fig:match-default}. To
virtualize pattern matching users can provide their own type signatures and implementations in \code{__match},
on implementations of the zero-plus monad, and implementations and signatures of the deconstructors.

% Basic Scala
\begin{figure}[ht]
\begin{listingtiny}
object __match {
  def zero: Option[Nothing] = None
  def one[T](x: T): Option[T] = Some(x)
  def guard[T](cond: Boolean, then: => T): Option[T] =
    if(cond) one(then) else zero
  def runOrElse[T, U](x: T)(f: T => Option[U]): U =
    f(x) getOrElse (throw new MatchError(x))
}
\end{listingtiny}
\caption{The implementation of the virtualized pattern matcher with the original
 Scala semantics and with \code{Option} as the zero-plus monad.}
\label{fig:match-default}
\end{figure}


% Example of a single pattern.
If the object \code{__match} is in scope a simple pattern match\begin{lstparagraph}
p match {
  case Pair(l, r) => f(l,r)
}
\end{lstparagraph}

is translated into\begin{lstparagraph}
__match.runOrElse(p) { x1: Any =>
  Pair.unapply(x1).flatMap(x2: (Int, Int) => {
    val l: Int = x2._1; val r: Int = x2._2;
    __match.one(f(l, r))
  })
}
\end{lstparagraph}

% Example of alternation.
In case of multiple case clauses\begin{lstparagraph}
p match {
  case Pair(l, r) => f(l,r)
  case Tuple2(l, r) => f(l,r)
}
\end{lstparagraph}
the monadic addition \code{orElse} is used for matching alternative statements in order:\begin{lstparagraph}
Pair.unapply(p).flatMap(x2: (Int, Int) => {
  val l: Int = x2._1; val r: Int = x2._2;
  __match.one(f(l, r))
}).orElse(
  Tuple2.unapply(p).flatMap(x3: (Int, Int) => {
    val l: Int = x3._1; val r: Int = x3._2;
    __match.one(f(l, r))
}))
\end{lstparagraph}

% Example of guards.
Nested pattern matches\begin{lstparagraph}
p match {
  case Pair(Pair(ll, lr), r) => f(f(ll,lr), r)
}
\end{lstparagraph}

are translated into nested calls to \code{flatMap}:\begin{lstparagraph}
Pair.unapply(p).flatMap(x2: (Int, Int) => {
  val r: Int = x2._2;
  Pair.unapply(x2._1).flatMap(x4: (Int, Int) => {
    val ll: Int = x4._1; val lr: Int = x4._2;
    __match.one(f(f(ll, lr), r))
  })
})
\end{lstparagraph}

Finally the pattern guards are translated into the call to the \code{guard} function that executes the
by-name body of the case if the \code{cond} statement is satisfied.

% Explain how we leave it for DSL intrinsification to virtualize.
\todo{here add a link to later sections}

\subsection{DSL Intrinsification}
\label{sct:dsl-intrinsification}

DSL intrinsification maps directly embedded versions
 of the DSL intrinsics to their deep counterparts.  The constructs that
 need to be converted are: \emph{i)} DSL types, \emph{ii)} constant literals,
 \emph{iii)} captured variables, and \emph{iv)} DSL operations in the direct program.

 \todo{section pointers}

 \todo{pointer to the figure and add lines to the figure, also adapt the figure for the new translation}

\subsubsection{Constants and Free Variables}
\label{sec:constants-and-free-variables}

 \paragraph{Constants.} Constant values can be intrinsified in the deep embedding in multiple ways.
 They can be converted to a method call for each constant (e.g., $\trone{\mathtt{1}} = \mathtt{\_\_1}$),
  type (e.g., $\trone{\mathtt{1}} = \,$\code{liftInt(1)}), or with a unified polymorphic function (e.g., $\trone{\mathtt{1}} = \,$\code{lift[Int](1)}) that
  uses type classes to define behavior and the return type of \code{lift}.

  % Why do we use type classes.
  In \yy we use the polymorphic function approach for to translate constants

      \infyy{}
          {\tctx{\Gamma}{c:\;T}}
          {c}{\mathtt{lift}[T](c)}

  where $c$ is a constant. We choose this approach as DSL frameworks
  commonly have a single IR node for all constants and it is easiest to implement
  such behavior with a single lift method.

  The deep embedding can, given that Scala supports type-classes, provide an implementation
  of lift that depends on the type of $c$. The DSL author achieves this
  by providing a type class instance for lifting a set of types (defined by upper and lower bounds)
  of constants.

  % What are constants in Scala
  In \yy we treat as constants:
  \begin{enumerate}

   \item \emph{Scala literals} of all primitive types \code{Char}, \code{Short},
     \code{Int}, \code{Long}, \code{Float}, and \code{Double}, as well as literals of
      type \code{String} (\code{\"...\"}), \code{Unit} (\code{()}), and \code{Null} (\code{null}).

   \item \emph{Scala object accesses} e.g., \code{Vector} in \code{Vector.fill} is viewed as a constant. This allows
    the DSL authors to re-define the default behavior of object access. Translating objects is optional as
    leaving their original semantics simplifies the implementation of the deep embedding,
    but requires special cases in type translation.\todo{link to the examples}
  \end{enumerate}


\paragraph{Free variables.} Free variables are external variables captured by
  a direct \edsl{} term.  All that deep embedding knows about these terms is
  their type and that they will become available only during evaluation (i.e., interpretation or
  execution after code generation).  Hence, free variables need to be treated
  specially by the translation and the deep embedding needs to provide support
  for their evaluation.

  \yy tracks free variables in the DSL scope and translates them into a call to the polymorphic function \code{hole[T]}. As the arguments
  \yy passes the unique identifier for that variable:

    \infyy{}
          {\tctx{\Gamma}{x:\;T} \quad x\;\mathtt{is}\;\mathtt{a}\;\mathtt{free}\;\mathtt{variable}}
          {x}{\mathtt{hole}[T](\mathtt{uid}(x))}

  In \figref{fig:translation-example}, the free variables
  \code{n} and \code{exp} are replaced with calls to the polymorphic method
  \code{hole[T]}, which handles the evaluation of free variables in the deep
  embedding. Each captured identifier is assigned with a unique number that
  is passed as an argument to the \code{hole} method
   (0 and 1 in \figref{fig:translation-example}).
  The identifiers are later sorted and passed as arguments to the Scala function that is a result
  of \edsl compilation. The DSL author is required to ensure that the position and the type
  of the resulting function matches the order and types of the sorted identifiers passed by \yy.

\subsubsection{Type Translation}
\label{sec:type-translation}
 The \emph{type translation} maps every DSL type in the, already
  virtualized, term body to an equivalent type in the deep embedding.
  In other words, the type translation is a function on
  types.  Note that this function is inherently DSL-specific, and
  hence needs to be configurable by the DSL author.

  % The type mapping depends on the input type and the context. For all practical type mappings we only had to distinguish between the type-argument position (\code{arg}), e.g. \code{Int} in \code{lam[Int, Int]}, and the others (\code{other}). We define this function as $\tau: \mathbb{T} \times \mathbb{C} \rightarrow \mathbb{T}$ where $\mathbb{T}$ is the set of all types and $\mathbb{C} = \{\mathtt{arg}, \mathtt{other}\}$ denotes whether the type appears in the type-argument position. In \figref{fig:translation-example} this function transforms all types \code{T} that are not in the type-argument position to \code{Rep[T]}.

  The type mapping depends on the input type and the context. In
  practice, we need only distinguish between types in type-argument
  position, e.g. the type argument \code{Int} in the polymorphic
  function call \code{lam[Int, Int]}, and the others.  To this end, we
  define a pair of mutually recursive functions $\ttarg, \ttother
  \colon \mathbb{T} \rightarrow \mathbb{T}$ where $\mathbb{T}$ is the
  set of all types and $\ttarg$ and $\ttother$ translate types in
  argument and non-argument positions, respectively.

% Gives us a number of interesting possibilities.
  Having type translation as a function opens a number of possible deep embedding
   strategies. Alternative type translations can also dictate the interface of \code{lam}
   and \code{app} and other core \edsl{} constructs. Here we discuss the ones that we find
   useful in \edsl{} design:

\todo{link translations to their later applications}
\paragraph{The identity translation.}  If we choose $\ttother$ to be
the identity function and virtualization methods such as \code{lam},
\code{app} and \code{ifThenElse} to be implemented in the obvious way
using the corresponding Scala intrinsics, the resulting translation
will simply yield the original, directly embedded DSL program.

\paragraph{Generic polymorphic embedding.} If instead we choose
$\ttother$ to map any type term $T$ (in non-argument position)
to \code{Rep[$T$]}, for some abstract, higher-kinded IR type
\code{Rep} in the deep EDSL scope, we obtain a translation to a
\emph{finally-tagless, polymorphic}
embedding~\cite{carette_finally_2009,hofer_polymorphic_2008}. For this
embedding, the translation functions are defined as:
\begin{alignat*}{2}
&\ttarg[T]   & \; = \; & T \\
&\ttother[T] & \; = \; & \text{\code{Rep[}} T \text{\code{]}}
\end{alignat*}

By choosing the virtualized methods to operate on the IR-types in the
appropriate way, one obtains an embedding that \emph{preserves
  well-typedness}, irrespective of the particular DSL it implements.
We will not present the details of this translation here, but refer
the interested reader to~\cite{carette_finally_2009}.

\paragraph{Eager inlining.} In high-performance EDSLs it is often desired to
eagerly inline all functions and to completely prevent dynamic dispatch in
user code (e.g., storing functions into lists).  This is achieved by translating
function types of the form \code{$A$ => $B$} in the direct embedding into
\code{Rep[$A$] => Rep[$B$]} in the deep embedding (where \code{Rep} again
designates IR types). Instead of constructing an IR node for function application, such functions reify the
whole body of the function starting with IR nodes passed as arguments. The effect of such
reification is equivalent to inlining. This function representation is used in LMS~\cite{rompf_lightweight_2012} by default
and we use it in \figref{fig:translation-example}. The translation functions are defined as:
\renewcommand*{\mathellipsis}{%
  \mathinner{{\ldotp}{\ldotp}{\ldotp}}%
}
\begin{alignat*}{3}
&\ttarg[T\lbrack I_1,\ldots,I_n \rbrack]   & \; = \; & T[\ttarg[I_1],\ldots,\ttarg[I_n]] \\
&\ttarg[T_1 \Rightarrow T_2] & \; = \; & \mathtt{error} \\
&\ttarg[T] & \; = \; & T, \; \text{otherwise} \\ % \text{if } T \notin \{T_1 \Rightarrow T_2, T[I_1,\ldots,I_n]\} \\
%&\ttother[T_1 \Rightarrow T_2] & \; = \; & \ttother[T_1] \Rightarrow \ttother[T_2]\\
&\ttother[T_1 \Rightarrow T_2] & \; = \; & \text{\code{Rep[}}\ttarg[T_1]\text{\code{]}} \Rightarrow \text{\code{Rep[}}\ttarg[T_2]\text{\code{]}}\\
&\ttother[T] & \; = \; & \text{\code{Rep[}} T \text{\code{]}},
\; \text{otherwise}
\end{alignat*} %\text{if } T \neq T_1 \Rightarrow T_2

This translation preserves well-typedness but rejects programs that contain
function types in the type-argument position. In this case this is a desired
behavior as it fosters high-performance code by avoiding dynamic dispatch. As an alternative to rejecting function types in the type-argument position the deep embedding can provide
coercions from \code{Rep[$A$] => Rep[$B$]} to \code{Rep[$A$ => $B$]} and from \code{Rep[$A$ => $B$]} to \code{Rep[$A$] => Rep[$B$]}.

\paragraph{Untyped backend.} If DSL authors want to avoid complicated types in the back-end (e.g., \code{Rep[T]}), the $\ttname$ functions can simply transform all types to the \code{Dynamic}~\cite{abadi_dynamic_1991} type. Giving away type safety can make transformations in the back-end easier for the DSL author.

\paragraph{Custom types.} All previous translations preserved types in the type parameter position. The reason is that the $\ttname$ functions behaved like a higher-kinded type. If we would like to map some of the base types in a custom way, those types need to be changed in the position of type-arguments as well. This translation is used for \edsls based on polymorphic embedding~\cite{hofer_polymorphic_2008} that use \code{this.T} to represent type \code{T}.

With the previous translations the type system of the direct embedding was
ensuring that the term will type-check in the deep embedding. We applied this
translation to Slick \cite{slick} with great success (\sct{subsec:slick}).

Interestingly, just by changing the type translation, the \edsl author can modify the behavior of an \edsl.  For example, with the generic polymorphic embedding the \edsl will reify function IR nodes and thus allow for dynamic dispatch. In the same \edsl that uses the eager inlining translation, dynamic dispatch is restricted and all function calls are inlined.

\subsubsection{Operation Translation}
\label{sec:operation-translation}

The \emph{operation translation} maps directly embedded versions of the
  DSL operations into corresponding deep embeddings. To this end, we define a
  function \code{opMap} on terms that returns a deep operation for each directly
  embedded operation.

The \code{opMap} function in Scala intrinsifies direct \edsl body in the context of the deep embedding.
 \code{opMap} can be defined as a composition of two functions: \emph{i)} function \code{inject} that inserts the direct \edsl body
  into a context where deep \edsl definitions are visible, and \emph{ii)} \code{rebind}
  rebinds operations of the direct \edsl to the operations of the deep \edsl. Function \code{opMap} is equivalent to
  the composition of \code{inject} and \code{rebind} (written in Scala as \code{rebind andThen inject}).

\paragraph{Operation \code{rebind}.} Operations in Scala are resolved through a \emph{path}. For example, a call to the \code{println} method
  of the Scala object \code{Predef}\begin{lstparagraph}
scala.collection.immutable.Vector.fill(1)(42)
\end{lstparagraph}
  has a path \code{scala.collection.immutable.List.fill}\footnote{Scala packages have a hidden prefix \code{_root_} that we always omit for simplicity.}.

This phase of the translation translates paths of all operations so they bind
 to operations in the deep embedding. The translation function can perform an
 identity operation, prefix addition, name mangling of function names, etc.


\paragraph{Operation \code{inject}.} For \yy and polymorphic embeddings~\cite{hofer_polymorphic_2008}
in general we chose to inject the body of our DSLs into the refinement of the Scala component that
contains all deep DSL definitions

  \infyyax{}
   {dsl}{\mathbf{new}\;\;de\;\;\{\;\;\mathbf{def}\;\;\mathtt{main}():\;\;\ttother[T]\;=\;dsl\;\}}

where $dsl$ is the direct DSL program after rebinding and $de$ is the component name
that is provided by the DSL author that holds all definitions in the deep embedding, and
$\tau$ is the type translation.

Alternatively the DSLs can be injected into the scope by importing all DSL operations
 from the object that contains the deep embedding definitions.

  \infyyax{}
    {dsl}{\mathbf{val}\;\;c \; = \; \mathbf{new}\;\;de;\;\;\;\mathbf{import}\;\;c.\_;\;\;\;dsl}

In both cases the corresponding \code{rebind} function can be left as an
identity. If the deep embedding has all the required methods with corresponding
 signatures all operations will rebind to the
operations of the deep embedding by simply re-type-checking the program in the new context.

% Example
For example in a simple function application\begin{lstparagraph}
Vector.fill(1)(42)
\end{lstparagraph}the injection will rebind the operation through the extension methods of Scala. The
resulting code will contain wrapper classes that extend DSL types with deep operations:\begin{lstparagraph}
VectorOps(lift(Vector)).fill(lift(1))(lift(42))
\end{lstparagraph}

% Talk about additional implicit parameters.
Finally injection in the DSL scope allows the deep embedding to introduce additional implicit arguments to
 all DSL operations. The implicit arguments introduced in the direct embedding are treated
 as explicit in the deep embedding. For example, the \code{fill} operation can be augmented
 with the source information from the direct embedding and run-time type representation:\begin{lstparagraph}
VectorOps(lift(Vector)).fill(lift(1))(lift(42))(
  sourceContext("example.scala",1,1), typeTag[Int]
)
\end{lstparagraph}

% Important the DSL author can use a convenient interface for DSL designing DSL internals.
In \yy we chose the operation translations that closely match the structure of
 the direct embeddings. This allows the authors of the deep embedding to use the
 DSL itself for development of new DSL components. In this case the DSL author can use
 the deep interface augmented with implicit conversions that all simplify lifting constants,
 calling operations etc. With such interface the previous example resembles the direct embedding\begin{lstparagraph}
Vector.fill(1)(42)
\end{lstparagraph}
except for the abstraction leaks of the deep embedding (\sct{sec:abstraction-leaks}).
This approach requires less code than than ``naked'' AST manipulation\todo{cite}, e.g:\begin{lstparagraph}
VectorFill(Const(1), Const(42))
\end{lstparagraph}


\todo{rework this paragraph and also in other places}
 In~\figref{fig:translation-example}, calls to \code{range} on the object
 \code{vector.Vector} and \code{pow} on the package object \code{math.`package`}
 are respectively translated to calls \code{range} and \code{pow} on
 \code{this.Vector} and \code{this.`package`}. For simplicity, passing source
 information (\code{SourceContext}) and type information \code{TypeTag} is
 handled implicitly by the Scala compiler. In absence of implicit parameters
 they should be handled by the translation.

\subsection{Restricting Host Language Constructs}
\label{sec:restricting}
% TODO restricting constants
% Rule out unsupported expressions.
The direct DSL programs can contain well-typed expressions that are not
supported by the deep embedding. Often, these expressions lead to unexpected program
behavior (\sct{sec:motivation}) and we must rule them out by reporting meaningful and
precise error messages to the user.

% Consequence of the translation => Ill typed
We could rule out unsupported programs by relying on properties of the
core translation. If a direct program contains unsupported expressions, after
translation it will become ill-typed in the deep embedding. We could reject
unsupported programs by simply reporting type checking errors. Since, the
direct program is well-typed and the translation preserves well-typedness all
type errors must be due to unsupported expressions.

% Leaks error messages
Unfortunately, naively restricting the language by detecting type-checking
failures is leaking information about the deep embedding. The reported error
messages will contain virtualized language constructs and types. This is not desirable
as users should not be exposed to the internals of the deep embedding.

% Custom type checking!
\yy avoids leakage of the deep embedding internals in error messages by performing an
additional verification step that, in a fine grained way, checks if a method
from the direct program exists in the deep embedding. This step traverses the
tree generated by the core translation and verifies for each method call if it
correctly type-checks in the deep embedding. If the type checking fails \yy
reports two kinds of error messages:

\begin{itemize}
\item Generic messages for unsupported methods:\begin{lstparagraph}
List.fill(1000, Vector.fill(1000,1)).reduce(_+_)
^
Method List.fill[T] is unsupported in VectorDSL.
\end{lstparagraph}
%\vfill %% sstucki: hack!

\item Custom messages for unsupported host language constructs:\begin{lstparagraph}
try Vector.fill(1000, 1) / 0
^
Construct try/catch is unsupported in VectorDSL.
\end{lstparagraph}
\end{itemize}
%
% Restricting the language is a piece of cake.
With \yy the DSL author can arbitrarily restrict virtualized constructs in an
embedded language by simply omitting corresponding method definitions from the
deep embedding. Due to the additional verification step all error messages are
clearly shown to the user. This allows easy construction of embedded DSLs that
support only a subset of the host language.

\subsubsection{Correctness}
\label{sec:correctness}
To completely conceal the deep embedding all type errors must be captured in the direct embedding or by the translation, i.e., the translation must never produce an ill-typed program. Proving this property is verbose and partially covered by previous work. Therefore, for each version of the type translation we provide references to the previous work and give a high-level intuition:
\begin{itemize}

\item \emph{The identity translation} ensures that well-typed programs remain
well typed after the translation to the deep embedding
\cite{carette_finally_2009}. Here the deep embedding is the direct embedding
with virtualized host language intrinsics.

\item \emph{Generic polymorphic embedding} preserves well-typedness~\cite{carette_finally_2009}.
 Type \code{T} is uniformly translated to \code{Rep[T]} and thus every term will conform to its expected type.

\item \emph{Eager inlining} preserves well-typedness for programs that are
not explicitly rejected by the translation. We discuss correctness of eager inlining
in \cite{techrep} on a Hindley-Milner based calculus similar to the one of Carette et al.~\cite{carette_finally_2009}.

For the intuition why type arguments can not contain function types consider passing an increment function to the generic identity function:
\begin{listingtiny}
  id[T => T](lam[T, T](x => x + 1))
\end{listingtiny}
Here, the \code{id} function expects \code{Rep[_]} type but the argument is \code{Rep[T] => Rep[T]}.

\item The \emph{Dynamic} type supports all operations and, thus, static type errors will not occur. Here, the DSL author is responsible for providing a back-end where dynamic type errors will not occur.

\item \emph{Custom types} can cause custom type errors since \edsl authors can
arbitrarily redefine types (e.g., \code{type Int = String}. \yy provides
\emph{no guarantees} for this type of the translation.

\end{itemize}


\section{Deep Embedding Implementations}
\label{sec:deep-embedding-implementations}

% Different types of deep embeddings that can be used.
% Identity
% Re

\section{Automatic Generation of the Deep Embedding}
\label{sec:deep-gen}

\todo{add the Amir's system}
So far, we have seen how \yy translates programs written in the
direct embedding to the deep embedding.
%This makes the development task of an
This arguably simplifies life for \edsl users by allowing them to work
with the interface
% easier, as he can still use the interface
of the direct embedding.  However, the EDSL author still needs to
maintain synchronized implementations of the two embeddings, which can
be a tedious and error prone task.
% that greatly increases the development effort.
%For example, a change in the direct embedding must be always applied
%to the deep EDSL as well.

% Two steps
To alleviate this issue, \yy automatically generates the deep embedding from
the implementation of the direct embedding. This happens in two steps: First, we
generate high-level IR nodes and methods that construct them through a
systematic conversion of methods declared in a direct embedding to their
corresponding methods in the deep embedding~(\sct{sec:yy-impl-def}).
%
Second, we exploit the fact that method implementations in the direct
embedding are also direct DSL programs.  Reusing our core translation
from~\sct{sec:translation}, we translate them to their deep
counterparts~(\sct{sec:yy-impl-lower}).
%% sstucki: what exactly does this mean?
In the translated method bodies, in addition to the translated DSL itself, we also allow
usage of the Scala library constructs that supported by the target back-end (cf.~\cite{techrep}).

The automatic generation of deep embeddings reduces the amount of
boilerplate code that has to be written and maintained by \edsl
authors, allowing them to instead focus on tasks that can not be
easily automated, such as the implementation of domain-specific
optimizations in the deep embedding.  However, automatic code
generation is not a silver bullet.  Hand-written optimizations acting
on the IR typically depend on the structure of the later, introducing
hidden dependencies between such optimizations and the direct
embedding.  Care must be taken in order to avoid breaking
optimizations when changing the direct embedding of the \edsl.

% While  these optimizations are not re-generated; only the
% components that correspond to the interface and the IR nodes are
% modified. Therefore, the DSL author is only responsible for
% maintaining analysis and optimizations in the deep embedding. A change
% in the direct embedding interface should affect only optimizations
% related to that change. However, this is back-end dependent so \yy
% does not provide any guarantees.

% Devil is in the details

For further information on how to use \yy's code generation together
with the core translation, and how to specify rewrite rules,
cf.~\cite{techrep}.\todo{fix this, this is the tech rep}

\subsection{Constructing High-Level IR Nodes}
\label{sec:yy-impl-def}

To make the generation regular \yy provides a corresponding IR node and
construction method for every operation in the direct embedding. By using
reflection, we extract the method signatures from the direct embedding. From
these, we generate the interface, implementation, and code generation traits as
prescribed by LMS. This part of the translation is LMS specific and applying it
to other frameworks would require changing the code templates. Based on the
signature of each method, we generate the \emph{case class} that represents the
IR node. Then, for each method we generate a corresponding method that
instantiates the high-level IR nodes. Whenever a method is invoked in the deep
EDSL, instead of being evaluated, a high-level IR node is created.

\figref{lst:vector_deep_ir} illustrates the way of defining IR nodes for
\code{Vector} EDSL. The case classes in the \code{VectorOps} trait define the
IR nodes for each method in the direct embedding. The fields of these case
classes are the callee object of the corresponding method (e.g., \code{v} in
\code{VectorMap}), and the arguments of that method (e.g., \code{f} in
\code{VectorMap}).

\begin{figure}
\begin{listingtiny}
trait VectorOps extends SeqOps with
  NumericOps with Base {
  // elided implicit enrichment methods. E.g.:
  //   Vector.fill(v, n) = vector_fill(v, n)

  // High level IR node definitions
  case class VectorMap[T:Numeric,S:Numeric]
    (v: Rep[Vector[T]], f: Rep[T] => Rep[S])
    extends Rep[Vector[S]]
  case class VectorFill[T:Numeric]
    (v: Rep[T], size: Rep[Int])
    extends Rep[Vector[T]]

  def vector_map[T:Numeric,S:Numeric]
    (v: Rep[Vector[T]], f: Rep[T] => Rep[S]) =
      VectorMap(v, f)
  def vector_fill[T:Numeric]
    (v: Rep[T], size: Rep[Int]) =
    VectorFill(v, size)
}
\end{listingtiny}
\caption{\label{lst:vector_deep_ir} High-level IR nodes for Vector.}
\end{figure}

% Side-effects

Deep embedding should, in certain cases, be aware of side-effects. The EDSL
author must annotate methods that cause side-effects with an appropriate
annotation. To minimize the number of needed annotations we use Scala FX
\cite{rytz2012lightweight}. Scala FX is a compiler plugin that adds an effect
system on top of the Scala type system. With Scala FX the regular Scala type
inference also infers the effects of expressions. As a result, if the direct
\edsl is using libraries which are already annotated, like the Scala collection
library, then the EDSL author does not have to annotate the direct EDSL.
Otherwise, there is a need for manual annotation of the direct embedding by
the EDSL author. Finally, the Scala FX annotations are mapped to the
corresponding effect construct in LMS.

\figref{lst:vector_deep_fx} shows how we automatically transform the I/O
effect of a \code{print} method to the appropriate construct in LMS. As the
Scala FX plugin knows the effect of \code{System.out.println}, the effect for
the \code{print} method is inferred together with its result type
(\code{Unit}). Based on the fact that the \code{print} method has an I/O
effect, we wrap the high-level IR node creation method into
\code{reflect}, which is an effect construct in LMS to specify an I/O
effect~\cite{rompf_building-blocks_2011}. In effect, all optimizations in the \edsl
will have to preserve the order of \code{println} and other I/O effects. We omit details
about the LMS effect system; for more details cf. \cite{rompf_building-blocks_2011}.

\begin{figure}
\begin{listingtiny}
class Vector[T: Numeric](val data: Seq[T]) {
  // effect annotations not necessary
  def print() = System.out.print(data)
}
trait VectorOps extends SeqOps with
  NumericOps with Base {
  case class VectorPrint[T:Numeric]
    (v: Rep[Vector[T]]) extends Rep[Vector[T]]
  def vector_print[T:Numeric](v: Rep[Vector[T]]) =
    reflect(VectorPrint(v))
}
\end{listingtiny}
\caption{\label{lst:vector_deep_fx} Direct and deep embedding for Vector with side-effects.}
\end{figure}

\subsection{Lowering High-Level IR Nodes to Their Low-Level Implementation}
\label{sec:yy-impl-lower}

Having domain-specific optimizations on the high-level representation is not
enough for generating high performance code. In order to improve the
performance, we must transform these high-level nodes into their corresponding
low-level implementations. Hence, we must represent the low-level
implementation of each method in the deep EDSL. After creating the high-level
IR nodes and applying domain-specific optimizations, we transform these IR
nodes into their corresponding low-level implementation. This can be achieved by
using a \emph{lowering} phase \cite{rompf_optimizing_2013}.

\figref{lst:vector_deep_low} illustrates how the invocation of each method
results in creating an IR node together with a lowering specification for
transforming it into its low-level implementation. For example, whenever the
method \code{fill} is invoked, a \code{VectorFill} IR node is created like
before. However, this high-level IR node needs to be transformed to its low-level
IR nodes in the lowering phase. This delayed transformation is specified
using an \code{atPhase(lowering)} block~\cite{rompf_optimizing_2013}.
Furthermore, the low-level implementation uses constructs requiring deep
embedding of other interfaces. In particular, an implementation of the
\code{fill} method requires the \code{Seq.fill} method that is provided by
the \code{SeqLowLevel} trait.
\begin{figure}[ht]
\begin{listingtiny}
trait VectorLowLevel extends VectorOps
  with SeqLowLevel {
  // Low level implementations
  override def vector_fill[T:Numeric]
    (v: Rep[T], s: Rep[Int]) =
    VectorFill(v, s) atPhase(lowering) {
      Vector.fromSeq(Seq.fill[T](s)(v))
    }
}
\end{listingtiny}
\caption{\label{lst:vector_deep_low} Lowering to the low-level implementation for Vector.}
\end{figure}


Generating the low-level implementation is achieved by transforming the
implementation of each direct embedding method. This is done in two steps.
First, the expression given as the implementation of a method is converted to
a Scala AST of the deep embedding by core translation of \yy. Second, the
code represented by the Scala AST must be injected back to the corresponding
trait. To this effect, we implemented Sprinter~\cite{sprinter}, a library that generates
correct and human readable code out of Scala ASTs. The generated source code
is used to represent the lowering specification of every IR node.


\section{Putting it Together}
\label{sec:putting-it-together}

% Section will follow the development cycle, DSL author, DSL user

% We will define a DSL and the dependencies.

% We will use the DSL

% We will generate

\section{Evaluation}
\label{sec:ch2-evaluation}

We compared the deep embedding generation of \yy with Forge on three Delite-based
 deep \edsls: OptiML, OptiQL, and Vector~(\sct{subsec:eval-deepgen}).
Then, we measured the effect of concealing the deep embedding by counting the
number of obviated annotations related to deep embedding in the test suites of OptiML
and OptiGraph EDSLs~(\sct{subsec:correctness}). Finally, we evaluated the ease
of adopting \yy for the existing deep \edsl Slick~\cite{slick}
~(\sct{subsec:slick}) and compare the effort of designing the interface with
the current version of the interface. We do not report on execution speed since performance
benefits of the deep embedding have been studied previously~\cite{rompf_optimizing_2013,forge}.

\subsection{Automatic Deep EDSL Generation}
\label{subsec:eval-deepgen}

To evaluate the automatic deep EDSL generation for OptiML, OptiQL, and Vector,
we used Forge~\cite{forge}, a Scala based meta-EDSL for generating both direct
and deep EDSLs from a single specification. Forge already contained
specifications for OptiML and OptiQL.

To avoid re-typing OptiML and OptiQL we modified Forge to generate the direct
embedding from its specification and generated the direct embeddings
from the existing Forge based \edsl specifications. Then, we used our automatic deep
generation tool to convert these direct embeddings into their deep
counterparts. Since, deep \edsls mostly consist of boilerplate the generated
embeddings have a similar number of LOC as the handwritten counterparts. For all
three \edsls, we verified that tests running in the direct embeddings behave the
same as the tests for the deep embeddings.

In Table \ref{tbl:deepgen}, we give a line count comparison for the code in
the direct embedding, Forge specification, and deep embedding for three \edsls:
\emph{i) OptiML} is a Delite-based \edsl for machine learning,
\emph{ii) OptiQL} is a Delite-based \edsl for running in-memory queries, and
\emph{iii) Vector} is the EDSL shown as an example throughout this paper.
We are careful with measuring lines-of-code (LOC) with Forge and the deep EDSLs: we only
count the parts which are generated out of the given direct EDSL.

Overall, \yy requires roughly the same number of LOC as Forge to specify the DSL.
This can be viewed as positive result since Forge relies on a specific meta-language
 for defining the two embeddings. \yy, however, uses Scala itself
for this purpose and is thus much easier to use. In case of OptiML, Forge
slightly outperforms \yy. This is because Forge supports meta-programming at
the level of classes while Scala does not.

\begin{table}[ht]
\caption{LOC for direct EDSL, Forge specification, and deep EDSL.}
\label{tbl:deepgen}
\centering
\begin{tabularx}{\linewidth}{ X X X X }
\toprule
 EDSL       &   Direct      &     Forge     &   Deep      \\ \midrule
OptiML      &   1128        &     1090    &   5876      \\
OptiQL      &   73          &     74      &   526       \\
Vector      &   70          &     71      &   369       \\
\bottomrule
\end{tabularx}
\end{table}

We did not compare the efforts required to specify the DSL with \yy and Forge. The
reason is twofold:
\begin{itemize}

\item It is hard to estimate the effort required to design a DSL. If the same
person designs a single DSL twice, the second implementation will always be
easier and take less time. On the other hand, when multiple people implement a DSL their skill levels
can greatly differ. Finally, DSL design is technically demanding and it is hard to find
a large enough group to conduct a statistically significant user
study.

\item Writing the direct embedding in Scala is arguably simpler than writing a
Forge specification. Forge is Delite-specific language and uses a custom
preprocessor to define method bodies in Scala. Thus, learning a new language and
combining it with Scala snippets must be harder than just writing idiomatic
Scala.
\end{itemize}

\subsection{No Annotations in the Direct Embedding}
\label{subsec:correctness}

% What have we done.
To evaluate the number of obviated annotations related to the deep embedding we
implemented a direct embedding for the OptiGraph \edsl (an \edsl for graph
processing), and used the generated direct \edsl for OptiML. We implemented
the whole application suites of these \edsls with the direct embedding. All 21
applications combined have 1284 lines of code.

To see the effects of the direct embedding as the front-end we counted the
number of deep embedding related annotations that were used in the application
suite. The counted annotations are \code{Rep[T]} for types and \code{lift(t)}
for lifting literals when implicit conversions fail. In 21 applications
the direct embedding obviated 96 \code{Rep[T]} annotations and 5
\code{lift(t)} annotations.

\subsection{Case Study: \yy for Slick}
\label{subsec:slick}
Slick is a deeply embedded Scala \edsl for database querying and access. Slick
is not based on LMS, but still uses \code{Rep} types to achieve reification.
To improve the complicated interface of Slick we used \yy.
However, since the deep embedding of Slick already exists, we first designed the new
interface (direct embedding). The new interface has dummy method
implementations since semantics of different database back-ends can not be
mapped to Scala. Thus, this interface is used only for user friendly error reporting and
documentation. The interface is completely new, covers all the functionality of Slick,
 and consists of only 70 lines of code (cf. \cite{techrep}).

Slick has complicated method signatures that do not correspond to the simple new
interface. In order to preserve backward compatibility, the redesign of Slick to
fit \yy's core translation was not possible. We addressed this by adding a
wrapper for the deep embedding of Slick that fits the required signature.
The wrapper contains only 240 lines of straightforward code.

We compare the effort required for the interface design with \yy and with
traditional type system based approaches. The development of the previous Slick
interface required more than a year of development while the \yy version was
developed in less than one month. The new front-end passes all 54 tests that cover the
most important functionalities of Slick. When using Slick all error messages are
idiomatic to Scala and resemble typical error messages from the standard
library.

This study was performed by only two users and, thus, is not statistically
significant. Still, we find the difference in required effort large enough to indicate that \yy
simplifies front-end development of \edsls.

\subsection{Compilation Times}
\label{sec:compilation-times}

\section{Discussion}
\label{sec:other-languages}

% Staging and partial evaluation

\yy consistently translates terms to the embedded domain and, thus, postpones
DSL compilation to run-time. Although, compilation happens in a different
compilation stage, \yy does not allow staging~\cite{taha_multi-stage_1997}.
\edsls can, however, achieve partial evaluation~\cite{jones1993partial} if their
implementation supports it.

% Yin-Yang requires a few things.
We implemented \yy in Scala, however the underlying principles are applicable
in the wider context. \yy operates in the domain of statically typed languages
based on the Hindley-Milner calculus with a type system that is advanced enough
to support deep EDSL embedding. The type inference mechanism, purity, laziness,
and sub-typing, do not affect the operation of \yy. Different aspects of \yy
require different language features, which we discuss separately below.

% For the translation (nice interface) type introspection. For the library macros.
\paragraph{The core translation and language restriction} are based on term and
type transformations. Thus, the host language must support reflection,
introspection and transformation on types and terms. This can be achieved both
at run-time and compile-time.

% Semantic Equivalence
\paragraph{Semantic equivalence} between the direct embedding and deep embedding
is required for debugging and prototyping. If there is a \emph{semantic mismatch}~\cite{czarnecki_dsl_2004}
 between the two embeddings, e.g., the host language is lazy and the embedded
 language is strict, \yy can not be used for debugging. In this scenario the
 direct embedding can be implemented as stub which is used only for its user
 friendly interface and error reporting.

\todo{expand heavily}
\section{Related Work}
\label{sec:related-work}

% Context: Hudak, finally tagless, polymorphic embedding LMS
\yy is a framework for developing embedded DSLs in the spirit of
Hudak~\cite{Hudak96csur,Hudak98sr}: embedded DSLs are \emph{Scala
  libraries} and DSL programs are just \emph{Scala programs} that do
not, in general, require pre- or post-processing using external tools.
\yy translates directly embedded DSL programs into
finally-tagless~\cite{carette_finally_2009} deep embeddings.  Our
approach supports (but is not limited to)
polymorphic~\cite{hofer_polymorphic_2008} deep embeddings, and -- as
should be apparent from the examples used in this paper -- is
particularly well-adapted for deep EDSLs using an LMS-type
IR~\cite{rompf_scala-virtualized:_2009,rompf_optimizing_2013}.

% Forge

Sujeeth et al. propose Forge~\cite{forge}, a Scala based meta-EDSL for generating equivalent
shallow and deep embeddings from a single specification.  DSLs
generated by Forge provide a common abstract interface for both
shallow and deep embeddings through the use of abstract \code{Rep}
types.  A shallow embedding is obtained by defining \code{Rep} as the
identity function on types, i.e.\ \code{Rep[T] = T}.


A DSL user can switch between the shallow and deep embeddings by
changing a single flag in the project build. Unfortunately, the interface of the shallow
embedding generated by Forge remains cluttered with \code{Rep} type
annotations. Additionally, some plain types that are admissible in a
directly embedded program may lack counterparts among the IR types of
the deep embedding.  This means that some seemingly well-typed DSL
programs become ill-typed once the transition from the shallow to the
deep embedding is made, forcing users to manually fix type errors in
the deeply embedded program. Finally, DSL authors must learn a new
language for EDSL design whereas with \yy this language is Scala
itself.

% Lancet
Project Lancet~\cite{lancet} by Rompf et al. and work of Scherr and
Chiba~\cite{scherr_ecoop_2014} interpret Java bytecode to extract
domain-specific knowledge from directly embedded
DSL programs compiled to bytecode. These solutions are similar to \yy
in that the direct embedding is translated to the deep
embedding, however, they do not provide functionality to
generate a deep embedding out of a direct one.

% For space reasons:
Awesome Prelude~\cite{awesome} proposes replacing all primitive types
in Haskell with type classes that can then be implemented to either
construct IR or execute programs directly. This allows to easily
switch between dual embeddings while the type classes ensure
equivalent type checking.  Unfortunately, this approach does not
extend easily to native language constructs, and requires changing the
type signatures of common functions.

% Quoted DSLs
